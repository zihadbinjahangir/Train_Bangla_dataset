{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train Bangla dataset",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preparation step:"
      ],
      "metadata": {
        "id": "PTe5AtwtkGUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first I download the hole dataset with it's captions.json file. Then I devide the whole dataset and the json file into to part for training and validation with 80:20 ratio. After that I creat a folder in my google drive named coco and upload traning and validation data into this folder. I named the traning image folder as train2017 and validation image folder as val2017 because the model expected that way. For uploading json files I creat a folder named annotations inside coco folder and uploaded the json files and named them as captions_train2017.json and captions_val2017.json."
      ],
      "metadata": {
        "id": "GhYllOAhkNuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changes that I make in the codebase for the Bangla dataset "
      ],
      "metadata": {
        "id": "9c3ragbCnzVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Changes I made inside configuration.py:**"
      ],
      "metadata": {
        "id": "cNr8XMoloJal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inside configuration.py I have changed the epochs size to 15. At first it was 30 but I am using the free version of google colab it is too much for free version. For that after some times it got disconnected from the GPU. Thats why I set the epoch size to 15.\n",
        "I also changed the dir variable and set \"/content/drive/MyDrive/coco\" Because it is my google drive file link where I uploaded all the requered datasets and files."
      ],
      "metadata": {
        "id": "Vt1u6QFjowQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Changes I made inside coco.py:**"
      ],
      "metadata": {
        "id": "MGZaUiDOJEye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABmoAAADwCAYAAAAAaTvxAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAMtNSURBVHhe7N0LXFRl/j/wjyDDZYaryEUEEUQcNREVLckWNcMla8vStWzN/GnuatZu7Vr+XPOn5d9y18q8tF7Wys1006iUZUVLKcNUVMQbKoLIiIIigzgjMsj4f55zgZlhQGa4it/3y+NwzlzO5bmc55znPM/TISQk5A4IIYQQQgghhBBCCCGEEEKI4M4dseqEv/LJaDSiqqqq+tXd3V14vyk4SK+EEEIIIYQQQgghhBBCCCGkhVFFDSGEEEIIIYQQQgghhBBCSCuhihpCCCGEEEIIIYQQQgghhJBWQhU1hBBCCCGEEEIIIYQQQgghrYQqagghhBBCCCGEEEIIIYQQQloJVdQQQgghhBBCCCGEEEIIIYS0EqqoIYQQQgghhBBCCCGEEEIIaSUdQkJC7kh/t6Dh8H/1TXT3kmYlNw6+j5M79khz9fGG8+C30X1oODw8FDW1TaXpyPh4HiqkWUIIIYQQQgghhBBCCCGEEFvduSNWnfBXPhmNRlRVVVW/uru7C+83hXuwRY0K7mM/R9RoNbxMK2nas24TMPeT9diyYS7ipEWkacTNXIrVG7/F8mnSAkIIIYQQQgghhBBCCCGkBbVSPcceFH08GvsXilPGQZ20vAF8/4Tgvgo4GHUo3PEhDr5b8zv722trmnA1+ncLgFKhkBaQptJDrUawNx1XQgghhBBCCCGEEEIIIa3j3muQEhIAD/Zy++x25B1MgdEoLiaEEEIIIYQQQgghhBBCCLnX3HMVNc5+/sJreVm+8EoIIYQQQgghhBBCCCGEEHKv6hASEiKOiGMpYCaCEh6GX4A3nDuyeSNQfiULBTs/R3HeUfEzphz6Qxk3A90Gh8BD6kmqsjgfmt2rcOW0lc+bcB69FdGDVbhx8H2c3LFHWmqdLZ+1zVQsTx6L8LJ0LJmwBNrxszFjbBSCpZ3Ra9Kx6cP5SDwtzNboNQav/c9YPNwrAEpHcZGhrBA5ezfg3ZWp0IqLaihjMenPkxAfHYzqHrfKtdAc2o5VH29Gpl5aNm05kp8Ol2bqIWzvfKRKs22StC/6A0sw7u9aTPjzDDzD9l/J979Kz/Z9Ez5akIgs8dMSJWInz8akUSwM5ANVZYD2Yjq2f/IRNh+TD5SJBoVFHBZsno0Y3izrLnK+ScCstdIMIYQQQgghhBBCCCGEkPvGnTti1Ql/5ZPRaERVVVX1q7u7u/B+U7BeUdP7Q0SPVcPZanubHJxaOBNl0pzAIR7+M/6E7j7SvIUbBz/EyR0p0lxt9Ve+TEPo288gQJqrT2HSaOQdkWZsJlfUZCLtUg/E9lJKy01YVIooR83Fmldj4S1VClgyZCdizmvraiogerF1LGLrcJXmLRWnYdkfFiGF10G0x4qaY2nID4+F2sqhFSpxFsh7ocbUZYsxNkKuybJQpUXaxy9j0a6aypqGhwVV1BBCCCGEEEIIIYQQQgipXytX1ITAZ8oa9OxqQHHqSuTuT4HRwBYrwuEc8iQCRodAu+JPJhU1Krg/+yX69FZAf3Y7ziV9iXKdFnAIgVOvaeg+JgY+LlrkrnoOV4qlr1hoUxU10pzhUjo2r1+H7fs0UMTNxtI/xiFAYUDm2qcw5xv+iTFYvGUGopTss0Xssys/wuZDbL99YzB2ylRMiguGAgZkbZqIN/7FKxSCMWP1aowJZn/qc5C0Zgk+36WBXhmM+N/+EZOeVguVDNq98zFxcTpfQY0RC7DlzzFQNkOlzNQVyRgbJs3UKQeJCbOwTpqzmVmlkwGFBzbjn+u3I02jQNyfl+KPIwKgKM/EumfmIJF9Injmaqx+XDhQyPnPOiz5LAUavRLBo57DH383Fmpf9lZxGuZPWgTxSNkaFjXk/adKGUIIIYQQQgghhBBCCCGylqyosdJmxgcOUkMG460isZKGM+Sg4tyHuGBWScO4vAj/XuwLl1KQtXmlWEnDGfNReWoezv1cyGa84dO3v7jcZmuRt3A09ktTxkGdsJRX6sjL5Mn+ShpTBmh2LMLEqfOxeZ8G/La+NnUJ9l3k7ymg4pUE3HPDxZYhZen45BX2WV4xwBWnI3HJdHx0gH9TAfWQ5yA0IIl+DoN43YNBg6R5s7CKV9Lw5XoNUta/gbe25bA1syMVNQZxfHl7xPY95d2JmLJgM9I0wpFF6t/3QcPfc1WxmMdF4TnxQEGz7W3MWskrafhyPTS71uGNeYnI4QfKtz/GjODLGVvDghBCCCGEEEIIIYQQQghpI6xU1BxF6cEcVEIBv9HvYdAra+A/+Bk4uaik9y2E9YAX/5Uu8Rj09g48aDENflRsC6PyVQuvbZ8G6R+niZUoJta9koCEhJpWF3E9Q9gRAgqPJIpdlVlI3X1UHBPFNxgx/HVQsNAqyJC7B6ssx7lhNGszxQoLDx/0EJa0DHm/6p8a0ZrG1MV0LNtX68hiltk6YhDsz14MOdjzD/NRawQX1iHzAv9DCR+pkY7NYUEIIYQQQgghhBBCCCGEtBFWR6G5fWQmMj9LweUS9gGfEHQfPQ0DZ28VKm38elm0jHFRoKP05/2kR2exbYZemym81rK3COzwVYvrIlZYVV7nLYysOYcSs6ZK96kRYoUWbulQ55EqMa+NsTUsCCGEEEIIIYQQQgghhJC2wmpFDXc7n3dzNhoHl7yD4zvScUWqtAkbvxCh/UKkT5nI/bpWV2Sm06Gtm6QPtg8aqbJA6R0lvNYyzF/qykuUXiRWFTh51jXaTg/4NGCA+6bGx2hJTr7btBxTpc83uwNSpYqLqs5xiXr4mHdgZmtYEEIIIYQQQgghhBBCCCFtRZ0VNdVupUF/cB5yVzyLI6m8jYMCAf3ixfe43HyU8teuveF+919rN04V3xBeA/qOsdKdlhLxo/rDm/1luJQlDP6vLyoRxqBRhMVgkpWBUtS/jwEfmQVFGmmAfOucpdd2S1+IknL2qghHzO+sHKheMxDTjf9RCM0hYYnNYWGNwtHKugghhBBCCCGEEEIIIYSQZmalamUaur26BkEPPwNnD5OWMy5RcPUVx6kx3hZeRKW7UXyFvSrUUL+6Er49YuHQpips1Jj0ty1iy5Cv12P2qKa5Ia/5bp80qH0s5n7yGuIjeFUAn4/BhPnL8YdBfD16ZCZtFpd/k4JM3rUZO04TPlmMCUODxYHtlcGIn7kcC58MhgIG5OzbhFodeOWUQKiK8IjCbxdOQIyvsLRJtOgYNQ2SiJRjvIWMAurxa7D4uVgEiwcKwaNmYPk7YxCs4GP97MOmDL7cjrAwUaLjXwSCR76HGaOkMCGEEEIIIYQQQgghhBBCWkiHkJCQO9LfkmkIffuZOrudglGL3PXP4colaZ7r+iZ6Pj8cPi7SfC05OLVwJqqHYOnyDvpMjYG7NGtVaToyPp6HCmlW5jx6K6IHq3Dj4Ps4uWOPtLQeQ+Zi4/xYSLfugezNSHhtgzRjaiqWJ49FONvWxAZWTKinLcfip8OFgexrM6Aw9RPMWpICeUQV5agFWPOnmJptsaA/vRlvv74BtYfQD8bUZcsxNsLKmsrSsWTC/DpbirQJ7Dgls+OE3EQkvNKAI6uMx4I1ryGmzgOVhc3z3sCG09I8Y2tYVBvB4sefTeKHiZxvEjBrrTRDCCGEEEIIIYQQQggh5L5x545YdcJf+WQ0GlFVVVX96u5ebw2HTay0fdmE/PVf43yuFhViYwOB0aBD6YkUZK6YZl5Jw118H2dXrcS5E4XQm3ynTTiQiJST0u15vQapSV+LfzeBrLWz8NKSJGQV6WGokhZWGaAvykLSkpcwxaJiQL9rPl5+awPSLmhrPs8YtBqkfTYHk61W0nAarPvf+diwVwMt7xasvdOnYP7Lc2rvb7kWmr0bMGeyeSUNZ2tYVNu9CK9Yfo8QQgghhBBCCCGEEEIIaSFWWtQQQgghhBBCCCGEEEIIIYTcv1q5RQ0hhBBCCCGEEEIIIYQQQghpCVRRQwghhBBCCCGEEEIIIYQQ0kqoooYQQgghhBBCCCGEEEIIIaSVUEUNIYQQQgghhBBCCCGEEEJIK6GKGkIIIYQQQgghhBBCCCGEkFZCFTWEEEIIIYQQQgghhBBCCCGthCpqCCGEEEIIIYQQQgghhBBCWglV1BBCCCGEEEIIIYQQQgghhLQSqqghhBBCCCGEEEIIIYQQQghpJVRRQwghhBBCCCGEEEIIIYQQ0kqoooYQQgghhBBCCCGEEEIIIaSVUEUNIYQQQgghhBBCCCGEEEJIK6GKGkIIIYQQQgghhBBCCCGEkFbSISQk5I70dwsaDv9X30R3L2lWcuPg+zi5Y480Vx9vOA9+G92HhsPDQ1FT21SajoyP56FCmiV2UEZhwqsz8MSgYHi7Ssu43EQkvLJOmiGkobwRN/OvmDQsHAEsrVYrS8eSCfORKs0SQgghhBBCCCGEEEJIW3Lnjlh1wl/5ZDQaUVVVVf3q7u4uvN8U7sEWNSq4j/0cUaPV8DKtpGkqI2Zg6eqN+HbZVGnB/SQGs1csxqRhFpU0pBGCMeGvq7F+y0bMHSEtum8oMeFvn2L242rzShpCCCGEEEIIIYQQQggh1VqpRY0559FbET1Y1bAWNb7z0HtGLDyMOhTuXIv8QykwGqX3msK05Uh+Ovy+bEGi/N1SbHxODYWhEOn//gQfbUqHVnqP2CsOCzbPRoyHHul/H4f5u6XF94Mhc7Fxfiy8oUfOf9ZhyWcp0Oil9wghhBBCCCGEEEIIIaQNoxY19QkJgAd7uX12O/IONnElzX0uJiwEvN2D9sAnmE+VNKSx+gXAm70YTm/HWyupkoYQQgghhBBCCCGEEEKsuecqapz9/IXX8rJ84ZU0nR6dlcJrSXG68EpIY8R1CRBeK6/ng+poCCGEEEIIIYQQQgghxLq6uz4LmImghIfhF+AN545s3giUX8lCwc7PUZx3VPyMKYf+UMbNQLfBIZCHo6gszodm9ypcOW3l8yZs6frMpm7SGihu/hbMHiJWUtTLojs0+Xs53yRg1jdxmDFvGh4L84bCkb1p0CJnxyq89Y80k5vUSgSPeg5TxwxF724BUMrDdpRroTm0Has+3oxM0zvaIxZgy59jgEPLMO5LJea+9gxiutb3+xJfti1/eg6xvUzGmtEXImtfIjasSTJfh4mpK5IxNgzi/qyVFtZB/fhrmPrsw1D7S8etygB9cQ72fP4uVqVatMWRupPTH1iCcX/XYsKfZ+CZ6GBx/6v0bN834aMFicjin5X3mX327dwnsHC8GkpHAzT/WYTpPwRj8f9ORZQv+1xxGpb9YRFS2mQNwFQsTx6LcGmubpbdoUnfEwbaXwLt+NmYMTYKwVKC0mvSsenD+Ug8LcyKfGMw9ndjET9IjWBvKULVExZiGGuQNO51ZP5uIf5npBoBUhBa/X2BElHj/4ipv+6PYF+lGP/YOrQXM7Hn3x9hnWV4S+T0IYT7glRpaR2UsZj050mIZ/FC3o0604WNx0nc5xwkjkuCz7I/IK4L+xz77rr/WYKi/3kPfxwVzvZQj5xtb7N4L8RCQgghhBBCCCGEEELIfa4luz6zXlHT+0NEj1XD2Wp7mxycWjgTZdKcwCEe/jP+hO4+0ryFGwc/xMkdKdJcbfVXvkxD6NvPQHw2v36FSaORd0SasUFjK2o0h1Lh1C8OAfIN5moG5HwzC7PWaqT5+m/gG9jvz2G/X32rWKq0UJYVotAloAG/zygnYOmGSVDLFTQWzCph5N+XZutmWqGgRPxf1+C1obxTK2v4Ns0xv+EtV9QcS0N+eCzUVlZYfTNfrqg5nYUbvdQ14V6WhUxtOKK61RyEwtQ5mLIkU5prSxpbUZOJtEs9ENvLyoESKifmQ672qD/uapH+4cuYv6umlkOstDCgsKgSAXIlmymL3+di/rweC0bUkQLNPt/Q/baIh73Y9xax79URZ2tXytl2nOTKqazT/lD3qok/moxM+ERH1cR/QxY2PPUGNkuzhBBCCCGEEEIIIYSQ+1dLVtRYqYoJgc+DvJLGgOLUD3HwvdHYv5BN781ExpcpuFxikD4nU8F97EyhkkZ/djsyP3hO/Py7L+Pw1nSU3ALcB0+GH28F0UalLhiHhIQEcfomR1zIK2XkZfJkUkljKnhQHAIc+YDpyzBrEvvcuDnYcIzfVVYgfMhYBIsfExi0GqRvXYY3pkvrHDcdi/6VKYwHowgbjrHDxM+Z8eCVNAYUHtiA+fz3J81HUi4Ph9q/H/w/jwmVNIZLqVj22kRp2ydi1uJ1SMnWwlAlfdBej/8VU4VKGpPtYeuY+PY6pF6QtunxqZhk5d65sh+vpBG/t0jY/4lYsruQ/RJ/Lx5jxY8JlLySRpuOZeOWIZ3XCnqoEdWN3+B/A2/sKhQ+ExASI7zajt/oT0by3aYVU6XP22odZslxJmGJuP1CpYy8TJ5MK2lMeEQJlQ+GS+nY8O50jGOfnbgkFYX8QLH34p8WPyYwlKDwZArWLZ6FidLvTnxtGVI0/MPeiBnznPg5Mwqxkkafg6QP+e+Pw/R/SGMSWf4+C5WxD/FKGj0y/7UI08eJ6xg3/Q0s25oJzXW+nsYIxow/SZU01dvD1sHSxbKtWdDy+Oobi0mvWglrW44TW4+6lxh/xm0TKzaDeSUNj2OT1iGznC1QhEA9QniLEEIIIYQQQgghhBBCWoyVihofOEgPnRtvFcEo34c15KDi3Ie4sOJP5q1pXF6EP39K/VIKsjavRLlO6gbJmI/KU/Nw7md+U90bPn37i8ttthZ5vOJHmjIO6oSlvPWNvEye7GlN0yS0mVj3l3GYtTIFOcVsXp+JzTtPQWgAoPIxaWGwDm9MnI7569mxkkdW12uQtmkO9uTyGW8ERAhLLYitVKYs2Ix0/vvF6Vj1XaaV32eh5yL9UalD4SW5SyotcvYmChU3b6yXFnG754s3xaUpUdgGsbWDvEycaioUJoxUCy0Q9Ic+wSx5exjtoUQs+cNHYqWEQo2Y563U1Bg0SHl3orAfacL+a5H6930Qbpu7qljMM6VH5tYlSNGnQCOtw5CbhCVrs5Clk45du2WAZsciTJw6H5v3aYRw1qYuwb6L/D0FVCaVnqmLp2PKX5YhcW+OWNHCaLNTsOzfUvzw9UessNQCr6CYPAurdvHf10OzbQnSLvA3zH+fzwtdnXFlp1ATbbOQsn4Opk9fZNL6xrSCKgFLDogf5q2lzOOTSWua6OcwiNc0sriRNE/eHoali5T1b+CtbTlCRZ531BjE8eVmGn6cBJf2YBWLP/qzheI62P/p/5yPlOISGCqFBYQQQgghhBBCCCGEENLirFTUHEXpwRxUQgG/0e9h0Ctr4D/4GTi5qKT3LYT1gBf/lS7xGPT2DjxoMQ1+VOwySeWrFl7bI/3ZlNrjesiVIBbdSHnHzcDi1Rvx7Xbz1ht8bBiBfFPcVFkmvrYcO2OXBmK7EnOZ2/YhxwAouo3B4s0bsXr+DIwdGtyA7s0aIg5qPr4HW3P6NynSzW5Tqdh5QqwuCOhipQXExXQs22f5Lfnm/iz2l4myU0j9xvSzBmT9sE6s1Gk08wqFOqc6WlA1Pw3SP6499tC6V8TtMhs/SBmFCXOWY/3mb83iU7LcpZ2jAk7CB83lpM63GN9Hj1OFtUMU2I6dGTxMlYiauRFbPl2K2c/FI7ypWsgNCha6tzPk7sGqWmPjsCOxNlMMcw8f9BCWmLLhODGaQybdCnKXfsY6ay2aCCGEEEIIIYQQQgghpAVZHYXm9pGZyPyMd3PGPuATgu6jp2Hg7K1CpY1fL4uWMS4KdJT+JPULnrIcn84eg6hg75pWCk3t9DrMemuV0M0ZHL0RPGQMpv51NbZs34jVcyYgqlE1Nj3g48Ff9SjJEBbUklbEIk0TqZBeRZUwXJf+JJI4zP1kMSYNC0eANJB+09MjZcHLWPRVptCaRumvRtzvXsPyDclCpc2MuLrGKmqYuC5iRW7ldWvVjtw5lJg14bOfocqiSueWvokq/gghhBBCCCGEEEIIIcR+VitquNv5vJuz0Ti45B0c35GOK1KlTdj4hQjtFyJ9ykTu17W6IjOdDm3dJH3wfhWDSXHh4LfTDZpUrHtbHj9GnORux5rE6SRxfBo+/s3aJKRfkCpthk3Cgv831WxMG9topJvmSvhECwtqifU378CsbWruMWpahvJ3TyBGaNmiRdbWZdXjxwjT39NrtTSxnx5pn80Rfp+Pf7MhNQu88Q2vtBkzewXmNmJcl3SpYs/JU6ywqU2uHCSEEEIIIYQQQgghhJD2qc6Kmmq30qA/OA+5K57FkVT+1LsCAf3ixfe43HyU8teuveF+91+7dzgqmqi7MFkUAoSb6uLYK4mHxC7CRGoo5bFlmhIf/+abVZj/h4kY91aq0FWaIiIKJqFno1MoEYYICkDUaCtdmynj8Vhf3sLCgPyzph2+EUETt6KKCQsRKv5wIQ1vr0+pHj+GU/pY7/Kssfj4N5uXvIEp4yZiw0lh9Bj0H1Z79JiG0heVCGPQKMJiMMlKglP/PkasWCzSIF1YQgghhBBCCCGEEEIIIe2LlaqVaej26hoEPfwMnD1MWs64RMHVVxynxnhbeBGV7kbxFfaqUEP96kr49oiFQ5uqsFFj0t+2iC0kvl6P2aPuUv1SrBNuHKPbcLw3Mx7BTVZbw35X+GElegwbI/6uMhixT7+G5ZuXIr4Lf6/xpi7bgtWLXsPYYeqabWfr6d/HG+7SrP00SDwgDe4+bC5W/6lmrBLvQROwYMUfEMNbP5RlYnubbkDVkmPU5EiVW0pEPb8AEwY1rqswU9ryG+IfgWq8KP2ud0Q8pi5aj41TosRKnMYaMRfrNyzHginxiIqo2XbviMEIkWYNVY0Yif+bFGTyVlos/5jwyWJMkMdTYnE2fuZyLHwymO2HATn7NiGTLyeEEEIIIYQQQgghhJB2xmqVSgevEASPmIboP67Bg2/vEKfZ89CnrwowapH3k+ko3ekoTtqDklvsxzzC0eP5eRj8V+k71dNKmPVe1OUd9DF5P3qwWAHkPvjNmu+8+g6chaWNNGQs4vtINRauAYgb84z4d12+SUG60NhFifDHX8PqLU3VFdZ2pJ0Wmzx4D5oh/u6W1Zg7LR7h7OAYyoVanMZzVCI4Oh5T5yyt2Xa+nt9FCTfAtXu/Nh+030aatauQlCu0gUDwKHGsEr6OjQsnIcZfwXakEKn/XAJqTyPTIHGfWLml8I/BpIUba+JT8hYsaES3YZnbMoVWUlCEY4z0uxuXvYax0QFQsPjUNDFKAXffcMQ8+xoWL6vZdr6euC4svMtzsOdfadJn7ZGKJf9Mh5DkfKMwiY+nxNfB4uxrj4cLcVZ/OhGr1tJoMoQQQgghhBBCCCGEkPbJSkXNJuSv/xrnc7WoMLnTazToUHoiBZkrpuHKJWmh7OL7OLtqJc6dKIS+ae4ON50DiUg5KfUJpdcgNelr8e86pWLRa0uQdLKp90WPxHfexYYDGuirpEVVBuiLspC0ZCI+OtaIVgkmNr2/DIlsHVrTih9pPSn/mIOXFze2CiUL6155CUv+k4XCMpN1GPQoPJmEJVOnYMmuphsdpT3QrH8L8z9Lg0bbxInj9DK8sSQJOaa/W66FZu8GzJmU1DQD5e/+CEvWpiCrSA+DHG85vh6WtpZMn4V1F6RldtLvmo+X39qAtAtas3UYtBphbJzJr29gsY4QQgghhBBCCCGEEELapw4hISF3pL8JIYQQQgghhBBCCCGEEELue3fuiFUn/JVPRqMRVVVV1a/u7o0fbETWnob/J4QQQgghhBBCCCGEEEIIuadQRQ0hhBBCCCGEEEIIIYQQQkgroYoaQgghhBBCCCGEEEIIIYSQVkIVNYQQQgghhBBCCCGEEEIIIa2EKmoIIYQQQgghhBBCCCGEEEJaCVXUEEIIIYQQQgghhBBCCCGEtBKqqCGEEEIIIYQQQgghhBBCCGklVFFDCCGEEEIIIYQQQgghhBDSSqiihhBCCCGEEEIIIYQQQgghpJVQRQ0hhBBCCCGEEEIIIYQQQkgroYoaQgghhBBCCCGEEEIIIYSQVkIVNYQQQgghhBBCCCGEEEIIIa2EKmpIO+aN3/T+DF+Ex0MlLSGkbQsGYn7A7fHvSPOE3Ie6fobb0zfhjkKaJ4TYQY2XBmzCP4L7UxmIEEIIIYQQQu4BHUJCQu5If7eg4fB/9U1095JmJTcOvo+TO/ZIc/XxhvPgt9F9aDg8PBQ1tU2l6cj4eB4qpFlyjxupx/HZ1+AhzcrOJYZg5Gpppk4q/LrXWrzR2xvQpuH/7XkHu6V3WsyAlXhwTLg0I8vBqYUzUSbN1cuhP5RxM9BtUAhULia1qrlfY/8Xa6UZ0q4M/AGVT/bAnZvn4LRsJDrckpa3lBELsOXPMVBKsyI90v8+DvPrTUAV+CGlCD2kOVnZ/iA8MN9RmqvtN/Fj8VJfFrmhQfKHe7HGKC6vj9LDH688NgADg7yh6CgtZHJ3fYnXj0kz1Tzw+guP4hF/J+hPpeLN/xbhovSOmX7D8O2oYGlGpsF3S/fiU2mOmOsaE4cVj3Rhf+lw+MtteOeyuLy2Kmz6qgBDPaVZ2fVOeHe8EtZysjuPHUdlLMv5S/bBaflz6NCAeHHPm7YcyU/XPl8kJszCOmnOmjsJx2EYUussCaf5I+t5EscXC2c8hn6u7E/NPkz8Ko+l8vuAsz8WTopDP1UlivZ9j+kHGnQmbmYNDwvrYV0Gp9UPwOGSNGuq4zT8Y/Qz6KEw4Nz+N/H7S1nSG8R+zoh4pT8iPXU4s/4ksuvM9+4nzXBMXFToPVWNMPdKFP+Yhf376MrOOmeETlGjb6ATdMez8NM2HWw9XQY8PwSDugOFyQdwKENa2E45+Huh9xNdEdRZCafqE2Qd8baBcVA+fmbOZyHpy7ZwfrmHRYdiTII/HUvSfFQe6Pc/kQhxq0TBjuPIyKiS3mjf3GK6IvpBP3h6ONVcJ1zPQ+qKIpYbmlMNjcBDv/KB042LOLiuAMVW70vIZQBpVqJLP4rUnW3g3N2GyhONOV80KCwC/RE3JRSqOsLz3tC2y9l37ohVJ/yVT0ajEVVVVdWv7u7uwvtNoe7r+DZLBfexnyNqtBpeppU0xEQwJvx1NdZv2Yi5I6RF95mQwPcxi1fSXE/H0tRWqKRptBj4TnkPDzwcAg/TShrSfnXZhMoxPWC8dQ4dV7ZCJU0r0FYapL+AyobcXfDpiQ/+ZyQe6mZeSVMn/2AM9OcVQY5Q9u6JUeJS0gQuVsgXNCzgmrgipcPOV9ExpwJ3fIbi9oQl0lLSdAyorJT+NFbdk5U0jwwchBUvPYsP+kkLGiKyJ/p5OLITqgv8+wXjEWlx62rGsLi9Fn/+KR0ldxToMeRt/F/TXTs0TlAgRsxlF6vR0rxwUTYEY+aGIkBaYinoBfb+K/41LYP4TTz2G3GPOUsLSLui9kWYJyv5OjjDd4AXtQirS6AXQgN5GnCA6gFf+IlLW5EDfB8NQ+xrkYgIlBa1FequGDklEqH+ppU09aA4SEj7FuGDEJWYxoNife+LNO77VH+MeCwI3qaVNHVyRuAAHzjzQ+TZFaFqafG9pl3k5e0gLAJ90HeyGvHjLR84a0UuKkQ8H4kRL5tcX7Qhd0+jzWIPij4ejf0LxSnjoA31fb5/QnBfBRyMOhTu+BAH3635nf3UmkYSDnXfYAQoFWgXPcfk+KNbfEj1dNfWNB2n4X8HhkNxR4sD6e/jv63QZkxwZGZN3Fz4NQqlxQ3S93mE8ofVbxXi/NZ5Jr/DJmpN0w5Ng3HcUBgdKtBx57twaK1HIHbPx7iEBCQI0xKk2/oQG28lYZJW62tNw1Xelm72Vxoa9NTHxIf7wZ+dtQxFmdj4z3/jqaVfVk+1W9MwRRocLuI1XlXQnzqLXeLS2o7tNfmtvciVFpN6yGEHA/Tl0p9WOeK58TVxotuSTg1oUbgHDl/8DU6lgDHyKVRFDZWWt2NrZ0npjk+JyJEWN1THbd3gPF+e6mtNwxlhkCrXDBU1laX3kvDuPdHVx8YSzpmzOFbG4q3xFoqOafCTtLh1NTwsOiQ/YBLG7wrp4250ZfPwf4fyYejgjYcHz0ObeHbHzxlu0OPGFWkeTnDlLYqul9dxHmCf5y3wSyuq33f2ECtodFep1N8uZRUj9zp/CKACxUdK79GnQlvA5VLkXeZpwAjd8WJUJ6lW4wTvXp3hrWrIkzQtyQlhvwqCs4MRN7PPIHXpASQtkqc6nthtYBws/NLkt5KLpKWEkDYvuwT5OjGNF6QVt//zTKfOUPdhZSejHgU7jyJ5sUneZbX1RQUuHylBBT9E1y8ir85G2RXIXlHzW6npbexItqHyhP3ni4aGRRsW4IHQIA84taXigbcSQd294NZGb5jXfy3fFoUECF1h3T67HXkHU2BkEZaQGiqM6x2PHizB6bLWYG7ZvXnade4aDJ6PlR1aiaJT6eJC0n7FvojbPkCHnG/heLgh3T+2D7+USumzXIe7F1c8EObPz6RaHE4+iS2lDWmiXoYPvkjEU0v/jYl1dXtG7HPtuvT0fzm0zdErhXEtHLYdYYUUZ9x+7C+4c++VVtowHa5cF/+qrL+WrX2pKMLba/+Npz5MbCPdnnHNHxanNB/iB57BesZiSrfWfwzPwZmXbnh3AeI8vxRR8KydX4CKCyw4wMmJvZgU+J2E3zCi6rY4T9qZWzqcWpGOpMVHqduzelUgb/1RJC1KR6od3Z7dP1zh04m9GIpwYmspdA1psU5xkJD2TVeGY8vENH5fdHsWogTvnawyOw8Z6RUNuoeq25eNXYsPIHlFXd2e3QPaSV7eLsKC2OSeu/Xh7OcvvJaX5QuvhJjp+CJ+Ha5iZ6EsfHfm3r3h7ewrNsC7WUqVNO3fLFQNDcYdXEXH5NnSMlKbJ7yF1rI6XCkRFpD2LudvcOSnetUAVA25D1rVENIssrD0xFHhKcIA9Yv4jbiw1bgJrWEqcEsrzqOzK3iDGpSW46awwJIT3NzYN8rkPuLYb3ixBezTumJxnhBC6hToKnZrUl6Bm1SbRQi5D6k6iyPQmpalCCFtV4eQkBDrHUMFzERQwsPwC/CG9OAayq9koWDn5yjOOyp+xpQ88PngEHhIzYcqi/Oh2b0KV05b+bwJ59FbET1YhRsH38fJHfXfXLfls7ZSBsfjuSljMFQdjAB5J6oM0F5Mx/ZPPsLmY6a9h8dhwebZiEE6lk3YDOWcP+KZIcHw5l/j38ndiVX/uwppJl+ZuiIZY8M0SBr3OjJ/txD/M1KNAGnUbr0mHZs+nI/E0+K8KfXjr2Hqsw9D7S99mP2+vjgHez5/F6tS5SvdqViePBaWQxHX1pCBwduIkXocn30NHrzrsxkN64d8SI9NWNTPG7qzK/HUie3S0joIcXYagvsFw0Ma78ho0KL46G4U7F4Lq72QeD0HvzFPIjjUW+zj2GhAWV46LiR9CL3cOsCqaQh9+xkEIAenFs68a9c/Hi/sQO8woDBpNPKOSAtbgzTAdeGO6ZiVGovZM59BVBclFLxHK70G6VtWYclXmWb96sfN34LZQ5TI+SYBs76Jw4x50/BYmLf4HXZ8c3aswlv/SDP7DpSxmPTnSYiPltIQV66F5tB2rPp4MzLNPixTIurJqZj09MMI95W2qc70yiijMOHVGXhCTqeMQcv24btV+MhiH0Ts98f/EVN/3R/BZr+fiT3//gjrqtNeDW+WB85+LhbqLtL+MvqiLPz8zQas22ZtHcwDyTA82wfI/w6Kf74qLbTw+GJsmRnFtojlH3+YjlUXpOXVlJj0wUZM6KWAdu98TFwsVfD5xmDs78YifpAawfJOW80/rJHyOI+G5BkV+CGlCD3qGSC+8YLxwRvDENaAQf5fevZ5/KabNCO7sBdPbdVIM/Vp+Hq8/ULxVnw/RPKKVZ4f3Nah6NwxbNyZh59My8H+fbDxhSggMwkTf1HgzV/HYGAwiyP8O5Va5P64F/MydbXiR9fAYLw0RI1eId5QOkkRqkKLi0ePYM2+IhyTbzjIv5+RhIWXeuLtX/dkMeIWLv6UjFdOq7Dw2ZHo58u+X5yJFf86ie9Nb1Q4uGDc0BgkDOgCb2EdVTCUXMLhn9OxIvuW9TjbGHK+3tC4IqWPO1f2wHnlZGlhyxmzaAtmRLNzryYJ06evYrHCgnISlm6cALVCi7QFE7HogLTYpvKEJfl8noPEhFlYJy21Rh5gnnd95nhYWtjElB7eeGlYDB4Kl+Nh3XFE6eyB8bF98WCPLvB3l/b79i1oC7KQvDMLW0xPflK8dTqxE+N338LLjw/Do/L4U7fLkPtTKt7J0EHMpTwwb9oYDGxA18a5u0y7QrT+PT1LKxN313MmVnrjlTi2zz18oeTbw/f5hhbn0/fhveptEon5jQbJH+7F8QcGYfJD4fBXsuPEx5y5fAJfbT+J75o8IU2D8U9/RaVXGZxWPwCHS9LiOsXg/4a/g4e9DTj185N4taX7SJIHOJVm61eEQ4vyAGuDrtahKQatde7WCRGjAmsGGjdW4voFDbL+cxXFUqsn9ilpkNNryFx6DtceCMHAOH948sycfz4nF4e3lta+GezijIBH/BEe6VszgO/tClzXFFj8PiMdK4fDR7H7544IezIEEd08hG0yGspwcfc5HDts5UaLpxJhj4cgPFjFrtuENVioPTCrOLh6CEI6u8KBf+V2ObRn8pGRzPbBWhnYwRG+v+oG9QAfeLpI56TblTA6sH1yaOzAr7YNSCwOysviyuLLcJnMB9R3hvF6Pn5ZdRkVg8MQO7wz+8Vy5O84iWMmT0s7BHkgPJaFMzumKuEkbITxlg5XjuTj+I96oWsRS1YHXzZlORiwfJwGdRLjBltH5bVryN5zAblnGv/ktr0DEtfaDxZnK+EkxK3C5AM4lCF8zEYeGDSXXc9Kc3WzEj9YvPF7NBiRUTXH6W5hYZcGD7DcyEGxbRgAXwiLoQHwVvF0xPZbV4b8fXk4xZ90Fz8ikn6zcAcLn3wv9P2NnF75d7TITj6P7Ozacco5vBPCh/khyF/OD1gcLCtDwX7zdage6wN2qmNhcxrXWXlzUB8lHG5eRcaGXFzxCcTgsV3h7XAH2oPHkfaDxTGQ8hw5f7KeZ9pJ2m/h2B9g+aDJeow6lpZ2sP22lpbs2SYFy5/jghDxgJyv1RMetuTl1fHJet4opmNr6YLnH0GI7FuzDp73X8kswKnUMut5c3OGBWdLWq03vUn5hcV7YjxUifnQSWcEPRWG3t3FuFvvea/B6s+n6kzjdoSF2wP+6B0bBL9ODYwfHfKRuvwKnIZ3Q1/5nFFfecJO8jG+a34m52NmxHJZQ7rxb/B6mjXO2pmXs7wgiMXzMLWXeV6Qno/s/eVNd07iGnK+sDUs6kp7LB4HTYhCdHcnoOwyDn6ajyumCbOZwkKOC3dldgzksLOtnN3gsp3VY2pFHeWFO3fEqhP+yiej0YiqqqrqV3f3phsQlO9Fbb0/RPTUJxDcVaqk4dgnXQPU6DFpGsvqLDjEw3+GNPC5fJOVcfINQdj499BndLy0xB78BvcOPChNvJKGcx/8ZvUyeQodILxlt+fefA1jh4TX3FThHBXw7haLSQvfw9Re0jJTHr3x208XY+owkxvM/DsRY/CX96ciWFpUwx+DVnyGuU/WVNJwyuAYTP2/BYiT5kVKxP91I5bOjK+ppOHY7yv91Rgz+1Msn3avjuzVHPpjZJA3ezUg+9JdKmmqB+sPh5dUScM5KLzhN/gZ9BgxXFpious76PPKiwgLkyppOAcFPMJi8cAra+HftWG3IKzqwn7bJC7zShouYIx5HH/w7a3w52PXtDB39WyseW8SYoKlCgtOGYyYyQuw8DmTuGlCETwb69fNxpiImkoLsOMb/uRf8N40k5TRayqWb5iLCSYVKAJXbwQPm4TFn8xFfK1VqDH2vTVY/HsxbVT/vpxeX35OWiBRxmPBmsWYZJpOGYV3MGInL8aa+fEstZmL+fNyLJ4ci/Bavx+Dsb//o0VaZat4bik+nT0GUfwGvPx5hqfV+N9PhcUWVbuj7gOe5Tuc3iwusOY/iTgqPDkcjKgxtXMVtnLE9OI7pkHalzWtsOJmzsbUUVE1lTRcdf6xAgtGWQ+7tuKREWPw7RvPSxOvPOGC8ZvqZdI0rU+LDwwe2W8YVv9uKCL9pEoarqMK/r2G4vXpw/CSlUOr7B6D1S89hof4zWj5O07eCHt0NN7pZxJpBMF4/flhGBjuW1NJwzl7o+uQkfjrWHbBJC2qplLjdV5Jw3/bwQVdB/bFwsfjxEoazjcK4x5yEf/mHDww76WxmMjTXvU6HKHwCcZDT47FihEetdJFizu+D478QsivL4x8nIoWlrTtqHhTPjgKT1hW/jHK52OgFpJeGjZIlTScXeWJNigyPBor/ufXeLSXaTyU40gMxktLZOOfGIPfsEJwdSUN19GF7Xc0Jk6yni4UndX4YPqTSAiXKmm4jh4IG/Ek3os1ia8tRBnYB5++LO2zvD18n919Ecm2afVTVtIeOmPg80/izUd7ipU0HLswUgZF4aXnWz5/qi0d3+XzyzoFenSt62x0v3KE95g+GPVCD/OBxh2c4Nk9DA8+bq12sAO8E/pixGOB0k0rhn8+IhLDnvWodXEVMLY/BsUEmg/g29FZ/P2poQiwUnx06xGCB6f3Re/u0oUz46DwQMjoKAyKtliDygODpoqftV5JU5sTS6ejpvLB1aVKGq6jK7z7RGLELCvbpFKh38wBeHBo55pKGq4j26eGrbIZOMDvqT5CJY0w5xmCiNGBGDyyszDoLhxcEfJoEHyFdzkPDJisRmSEl3Qhzzmw06UHAob2RdwEdqylpTJ+o6Hhgy8zDs6I+L10nEzW4dSpM3o/OwDDHmvYg2dNim1T6JQBtfeDxdnq+N7SWJyNfq0/BseYHyc5LEbywX0bsW38JviYudIkVxJ7hiJOXiZPzzeg9r9JObJtk8JCqKTh2H6rvBD6WH+MYttjGQc574ERGGGWXvl3OiFyfC9EBAofqRHoj4cm9EBYkGl+wOKgB19HP8RaiYOuD/XAYF5Jw2fcOiNyWCCingqBN/8+O5d5PxiKUNObnkH+GDbDPH+qzjNn9EFEkLSskRz8/FkeaZEP8v1+Ngr9LG+B2LNNnX0weBbPn03zNTk8eiDc4tjak5fbxgmhk3n+Yb4OnvcHxKgxOM5K/tHcYdHMadWMfyc8yMIjOqIm7tZ53mt2toYFS9vj+2PEkyweyJU0nBw/Zqith4WHD/pOiUKs6TlDLk+wc5L9e80rp2ryOvmGuSqmv3keyKZB0cJbLaeF8g+bOKjQd2Y/REd3qp0XDO+HB6KkRfcadlyDXxAraYzX8rB3tUUlTVsMC4Et5Wzby3b3AkdPT8//k/6WhMDniSnw9zSgOPVjnNi8AJrdX+DiL7/gaj67Yg1S4dbBFNTURarg/sz76BniCP3Z7cj6/P+Qt2sdLu79CUVXAuASFgSvbr1gOPk19Nb7NEDHHuMRGKSAoSANV8/lSUtlA+H1q94NegpPd/YLlNr9JBcw4NEEqHL+i8+WfYSlH32CzzZ+i5/O30IIS5kBKh8EuOch8Sf5edpQDH82FkHOCnbt4ghDUTo2LpmNOX9LxFmv/ojt6QOFtzcUP3+HA1JN5ICEiVB7O7LPKwB9DpJWzsHcdzbghxvd8fCgILg6d4bq5mb8ILeqeXwh3nsmlF1WG1B4YCP+9r9z8Le1G5F8phydwvoi1EsBn/AQOG7ficzKI/jvxo3YKEwF6PkE3zb+JPxTmPauvJxPW5B6Xvp9O/DWEqvefAkTJ06sZ3oKPS83bj2CsErMiC2Hs1aFj/5TfbekHk9g4sDe8Kk8ix2ZKTguLbUq7FVExgagY+lRnFz/NnL/uxIXf/wWlzIKcF0RBJdbJ1By3iQuOjyHbtMT0MlRh8KUlTi1VUoXB87julMkvLt2RqfgIBSl/2T+5E01OR5rcfXHZJP0I3EfAb8BQbj75ZsBpUe+gv6GNNvcBiZgoprFZS8fuFbpkfPfTzBn7kJ8knQWnlGx6OmtQOegIJz9Zi/kB3pD48YjtqsCnl34hZH4nfnvLsSKL0+gqtdDiGIXGT6eCvy07QDKEIwZi2bjQd53dHWaYGnv259Q7NADkZGd4aoKQWTgWST+XPPIsPr3i/DGI/6sSCSmjWXvvIv3PvkM3/50BJcrAhDqrsV338tNkZSY8P5iJASzPCo7CZ8sXICFy/+JjWwdeeyzPdVB6NwtEkHnErG3QPoKxmLWG48gwEmPzH/9jW3/e/jks43Vvx/kW44TSXtRE0PYfvzxJUS6s+3ZvQJz5rP9ZWl1Y8p+5BU7IihMhaLEnajdOGoa7jz2CIwuV9Fx2zx0qLPP0UvI6/IInujpCU/XDvgpKd2sVZZy8kuYzsIJmr1Y+kXNe6FDH0W4bj82/3MZli5egX+yPCD5YDFUfQegh6eK7UdHbNxRV5MtOY+rxKV9d0vPVXjxd3r4VLjhpy0KK/tpn27de+Ih6QZMvSqK8MuRq5AbGh09dRybf5EmvRcmhLOry+v52Hyq/iccRZ6IH9oN3uwonvklH1bbg/r0xP97Wg1PQxEO/3c3/l/yYazZdxwpxy6yfD8QEZ07I8zzGsurb0B4/kvlh2f6BUDhrIKqowFFGan4cMt+fHggGx4B4Yhgebm3mx4/H9eahKsKI3o74sKP+7BsRzpW7mX7cuAULrD41CeCnSu8PaDKPoc0fl6Vfl/ZyQeq65lY8ckhOPbtiS7undi5vAq5u77Be5c7YVQIW39VcfVxGDfmCcQHsXSRsw9rvtqH//fjMWkdVYgIDYAvy9e6nGHraMqhM+R8vcFxhUW88CkweivhcPkjOLT0WL0FeQh45An09PSEa4efkJRulvLw4pTp7LzOkt7PS7HR5D3byhOWBiBhoho+7HyRtfG/9R+jiBmo6uoMhzPs2DSi/GOVMhQLfjsA/uz0ayjKxOYtP+L93cfwLxZHMi5o4d+5I0qPFZqlkejwblDlH8SG7fuxLJV9lqXBn89cQVdW4PdXecL/znl8d0F6BFFOF2y5t8MtFB39UUwX+06hzC0IAwNcofJXwDG9AMfvVOCnIzXp2jXoAfTyElvPvPRtzXI+pZjFEfPvXXLtJuQplYXsnHLe2lN13pj3wsMIZdmOsM///hFv72Hp4lA2ylma7NPFE4pOgQjRnsL3Urdb0b35tnQUy3Y38pD8dQr+b+cx7LnkgId6+cHVxQvKS1nY0xRPtVYbiDsP8XNHBRwPf4IODSgTFFYNxFhWJnftoEfu+Z/Qoh0I6/TIYyfYs3sLYVB3gd/tPKQuPYMTfNlNZ/TsocSVH9KxZ9NF9hlxsFfdcf55NrE8r7vaHVeTDyD1K76sGB36B6BT1UWkLcnCMfaZvBz7Wyk4DWRl8Ie9WXmiEsXpp7F/83mc3MPWk16IopLbULpV4uIZOa50RKfBLG90cYVnZwUqL+ch/V9ncHRnAS7cckJIuApOnRxwM70EZSbj57ixi0fHvBxkfJ2H49/zfSzAuVPX4RjuC293d5aTXEH+ean06K5CaLQXFGwdbh3FbUr78jyy9l2BvosvAr1ZXHO7iXNHy4WHPDjfMSwOBjqYbc/ZA1dQonCGf5ArHLXseH9wHoXyxXmnTnjotyFQVpTgzLYsHPw2H2d+YtuUUQJdJxUC/b3R2fs6ck7Jjws7IODZB6AOcITx+mUc/eo0MpIu4gzfj6M34PRAZ3g5GXAt4ypKLB8/bLAqlByUwpxNl1y9EMqvDS8VWg1f1QNd0YWdFzw7G1GYnIHUHCchHikDWRrl+7viIkucfvBy6QD9OXm7nOH7AEsLP+Tg8PY8nObhnHYZF6/egU+kB9x8XFF1mn1Wvl717ISYpwPgygdf3nUKP391QTxOuXq4hfnAw/k2CrYdwU8/1BTefJ+OQv9gFgeyz2L/Fzk4/oO8jkq4d/eGTzc33D5VDG0jzqvVaYNPOrbfEewqubQYZ49bf1JYNaoXBke6AjdZeG83De9iVHYLQGd39pvZ7Jg35HHpWipwSd4WljbvRPH0wVsJZGB/ssl27jWNGw4ImvAAevo6AGVFyNiUhcP/YemCHadLLJ/07uEBV6UXvB1Zusiz7xFmMX5IM/UxO262xcFaAr3uGhbOv+qJYVFKMa1uzMbRFDE/OJ+nh2t3H3gFdIKi5BKKrkpfkH6zo9IVTndM4uHBEnRQs2tPV2e4O5Qg96xJhuPuBr8uLI9IykXmfy/gdCrbnwOXUWRwQZfuSrgFdkDpz6VCa1hFuB/bR5WQn11Pz8T3uwzo2t8Tbn6eUFUW4dDK07jarQsrs7jAWCzFEQcV+k3rCX9Hvj2n8UsiS0t8Heksz3FieU5XT/gFG3Dh0E12RO0k7beTlzvcHPTIZ/udxvd7v5wPOsHTz2Qd9myTgzMiX+oDVjQW4+G/s6rztfNn2fFxd0aHfC20JnmaTXl59fnCet4oxlGL97oHImaoJzpeL8D+z1heLsWPc0dLcF3REW4VZaxYanJUmz0s7Eir8jmsohR5B/XsSt2UM7o8wq5hLN4T46ECqi4+UnizczHfl58KUeLjga5+LrXOe7YxzadqpnrTuI1h4TAkHL+KYZlprfMFO0cGd4KX0gW+ZmEhxw8F3NxZCcRaecK7dnmi4aRjLc3Vxyz/Lyw1OUY34CH8hp4dv4YNxC+HZZ35ZkvkH+ybtublDkNCEBPJ8uaCc9j3abZ47mbfFfMCNyiuXEVRU7ZGb8D5wuawsEx7/CGNyX3RL8gJlZps/PRpMXSmcamZw8KQc7Vm++WyCm89syrXZL/YZLb/9pSzbSjbmR7Tc7fRhR8v3npGviaRp1p5l3Vyyxp5cnZuwH2rBjKvjBL48EYCAuOtIt6zk8iQg4pzH+LCij+Z3SCEy4vw509yX0pB1uaVKNdJHUIY81F5ah7O/cxTPSuY9u0vLrfZWuQtHI390pRxUIyWvOszeZk8NbaLqHWvT8T0BeuQclIjdeWhh2bfZsxJzRHmvDtbb71iyE3EnJfmswt5vu9apK9MQqZwkNzhY60vMm06lk2ehVW7+HrYOrYtQZpwh5GdoGoe+8KEkWrhaWb9oU8wa8FmpEs3BbSHErHkDx9BuCekUCPm+bb9VHyLcQ8Rm7Te0uGu96tcnNlFueh29XhHOhjLUlCW9DLO7TbvVs9h8HD4uwAlqfNYxpdSky5upeHGjrdxno9S7hsOT3uf+L40DydN4vKpXHEx7/rMNI7vX/gsiu7axUkzMGiQsngyZq1MgYYnjuJ0rHozCULKYPs91MqT5tBmYt1fxgnfyeFxV5+JzTtPiWlL5SN20xf9HAbxBiLs95PmyWmC0bP1rX8Db23LETJJ76gxJi1Y4jAhLpilFnZ8dszBFJY20oSN4l/LYt9jy94y6Syo24sYLuVRb7+2CinZUh7F1pG2aT7m7xbzqPBfmT4qoahpFVN2StxnRv796dMXIVVcJPGBs/T5yvJCFMr95hfnIO2bZZg18Y06ui+KwB0hzrDSbqmwoE6az9KQxQ9G8CCMNTvewXhxED+aBmT9/LlZ10ypi6djyl+WIXFvTnVXPdrsFCz7t9QNm68/YoWlbdNPu5Pw1NIvpWkvxGTBuySTl0nT2pP4SXivZSQM7AV/h1s49t8f8M5ZHS5K1yZavRZrvt2HY+UsBoUGI0FcbMKA3F3bMH13EYQW/JW3sCYtWwwLVoCXGtJJLuHNf+7FOye0qL5HaKzCL2czIN7f94a/n7DUhA7Hvuddm5XhojSOj+HCAXxwzIAz5RbFDedQ/KoHSxdFB7Dw2zx8r5eKYMI6TuKdAzyj8UaYuuVbNJjToMMVsdRh9J8kvLYsDT7/OUvIh4Kjx7LUZoLlLTE80AxZSPvMvNLF3vJEW/LIkL7oyh9BunwA8744iS0lVeK+sDhypkCDt7/IqNU14Kfbk/DKbg2+vyF9lrlYUoS308Xj480uuGsxanFsW1JNumC/n/x9Gg7zYHcKQqSVRoTNpmdP9OJFqrKTWPMl2+dSKV2wtPrdz3uxQijcKRDZN1gon5kpzcSKdfuw5rK47xcvZOIXofLfBSqL7hdaBSvrCNfhHgHoIyxoDQq48QOnq6wej0bViY9QY0Sl3voNWQdPBZxQgZvV50hnuPNoVHG79kMvNmMXsQ91Zr9vxJUfMrF/pw435Xvut6pwPfMy9m8T8x9LlefPIPWzIhRLJ9eK9MvIEz7qDBeLG8RXEk/i0M4yXL9Rs4/Gazqc+kW8G+spHANLlShMFrdJ6IrXUImCHy+Lx03lBD5Kj6yj8PRnOfJ+qNke/vninReRxy+bvKUxOiSeQ4Lg7VCBvG3ZyM6qrB5U2KgrR8FXOchlK3Hq7lPTEsWTlZG6s3UYinBkXT4KNMbqh5KMNypQ0ZgeaRqrIA+ZvGuzS3rpxoUOZ74pgs7A4ket7SrDsVW5yM4s50laxHb+ZlYBsoXrMDeoTPvGcesoPoVZcBGZJoMvGwtKkbmfH2gneAaaPKfp4oOwSDZ/ORd7vyrFdflOirCOIhxMu8ZmPBDYVy5gtgQVwqJ46LPjstkyvFm6ao1BiVl8Cg12YPHpKjI+zUNBgbxBRugyLyJtR5HwkItnH58G3WS0pvDLA0haJE3r88S4wW/GyMvk6S5dlDUtV4T3Z4X+mwU4yPOOa3IqYqldU4qMpEssT3NEYKSVvTay8NtwomYQ8FvlOHOAxyeW43hYPCt8+SoOrrsITU4FKuWin8GI6/s0yOUPDDjwCk5xcTXdJZz4nuWoBXrpPk8VCnezc4auqiatSBxiAhDCiobFP2ax7WFpSV7HLZ7n5OAUP+918kFgU5z3bl1D5roTOCbvN88HN59DIf+7kyf8pCKqXdsUFYgIPq9jcW4li4cm+VplESuzfZWLXIsbCvbl5TZgebl4c44dd9N13Chn54NzOLjH/KzX7GHRAmnVjJb95nIe3tK+sPJg8YFiMf1anPeanU1h4YiQKP7UKUs3O3lYmJ4vynDiszMo5PvTyQ8hli3gmMrzWdi9vmHliYYrwyGTvC41XTpDph81zwPZZF+3l/Zp0fzDBk7yjZzbVbglF1AZMS84iWP1PgHeBgmVNLzFsSMqsln82lBSu7uwNhoWsoaXs20s290jxPzHzFGUHsxhma4CfqPfw6BX1sB/8DNwcqkj+w3rAS/+K13iMcisiyZxGvyoeFRUvvdAF12+cZixaDU2fp2M5GST6WmptsVquVqPzMR1yJLmRCnQyDdqrchJnY8U+Q6GQI9ThWYLmDiouwi3opH+TUr1DY8aqdh5Qoy1AV1ihNeWkLpgHBISEu4ytfIYOGX5uOvqT++Aht/I9OqPqNlb0Wvsm3APsVarJlJ2DRASi8+ID2vF8QffXoOeXfmnfKBshW7JWsTFdCzbZxEL9VkoFKKg9QpJ/dmU2mMu7Z6PcTyOTJgvVnQMChYq1wy5e7DKyvhMmrWZYsWDhw96CEuY6MEI5jdpyjOR9LF5yrNqaDiEnihZHrXUNF1L0+rRYh7lE2CaR23Hzgy+c0pEzdyILZ8uxezn4hFuUpFqLhPb9/FKJQWC+XgyG1djwcyxiA1uYCVq6RV0kP6sk34D0nP5GTQAUb8xuXPZ7QlE8VkWHnv+ZRFGfFyeOcuxfvO35vv95xjxJqMjvwFGbOOCXl34+dAF/Z6y6IJNmB5DP36d5uQpxlNTZVn49phcCpJcLkFdjUT4GDgLn/81vnrNfB3V4+9YNjS8cQE/mY1fdAun0zXg9ci1dPOHH8/U/IfgfZPflqcVj4iZmbdPK5XOrOnYdE+p2EL/r3Tk8GDrEmVWSRo8JkqouNGf3IMNlidpu8oTbYkLy555BL6FY2k5OCMuvDsnFV4eFYdPX/mteZwaJeVZHa3suC4f3wsH2FQZLgr3PVq2kuORrp1ZLg4UnTpjPpaT5Kdj58VKb28PDBSW1MhNtxj/iTld3JI3ARvoriebZsQuHN34nRbD7eobYm5efMFN6OooN7t58TtxlTUXX51dIdwKKy2vruyxm6cKfjx+3byE7P22PC+oQ+6eUov+yitwXbxvWhvv9zyhB4a9Mci8yxG5n2xrjcavF+C0ydgqguqbqOZu3+Kfc0XoSH/4yhevCif4PtYVofx0ZTCi5iFKR3h35UeQXcSPN9mW6qkfwniQKFxr0l6YO4SfvVCCwta4sV+PwuMlwo3CagWXkVPP01rCuDyT1Rj1ZozZfotjvjjA0TQsbt4WfzuoK6JinKu7eHMI8kLUg+KBrqwweTy1uwre/DOBPRBv8tvylDCS38iTKydbSKASPjxT0xbzQ9M2SPGpMucKCuTKLBPGjBJc4WnL07yC8Z7n6QZvvkNuQYidUzt+jHm+K0uV7DTq6yy8mrmgQTa/aWaqunKyNufIzoie2hfxZusxGbPBIs+5eaYYWtP87CZLRxkWJzSJD4v/nO9wi/xMmGIQJXSV4w6PprgmvnwFGrl1kcxYjutCC9Wam3X2bJNvd/Gi7sqBy+b7Xh978nJbnClCLt8YzxC2jn6IfaozfIMdrN2wEzR7WLRwWtWdY/HQcj2Xi8QK1nrHl2oGNoWFEr688tNwBXmHrZQlbpUh/wI/UCp41rphzMsTZebnsfrKE/e4Fs0/bFBx+LJQvnHqFolRf+mDQY95wbtTXSmvjeugRMTL/YRKmuuZp5D6lWX8ErXVsBDZVs62qWx3j7Aa+24fmYnMz1L4/SM4+ISg++hpGDh7q1Bp49fLomWMi6LR56Q2odtULF89G2P4YOYtWH6uWw+ID57qUVJHLXdakfTINLGdMQVFq97BqSP5QncmXn2Ho8/klXjwr7zSZiac+UWNiQ4snhNLaSiSarjtFddFLK1UXpfb21o6hxLLuxLeSnbKYCoNaFAKUCmEG2+20SNlwctY9FWm0JqGj+kS97vXsHxDslBpMyNOujIwkbV2Fubw1kP8mHgHI+bxqZi7eguSN67G3PFRtZ++tsPmH7KEStuA6Ocgt/+RbxZrjyQiSVwkicPcT/i4PBbjZJBGUkDZAoeza+8hWD1xKPoFmozbcTd3bgstP2oYaj0JWY3laRQrGmoz9pwUUh6iflud8vBEPyHl4eg285TX9soT9pDjeT1xyJJzF3ww7Ukk9OsCb/nJtEbIKWv5So5wqcWP/kYdO11cVt06kTRc9XgRcyLFls/d1dUXUYMj+KWICpFTxPk4Pn4CHxBVej9uID971rw/5uVQCPcaq38jVPxNe8gtJiqlG/LNwcUD/Wr1e960ineew5XbgFNgKB6cIR2nvwzAgzE+bP8qUfh9AWrqwdg+25n560ob34apyZldxDMmlYCWHB4IwcgpkRZjd9Tj+jWcyGB5v4MSQY/1R4J00zthciSCPNj3tXnI3GtyU87Foe0+/NIUFZtNRNVZLBFX6OpKdRXQtVQXzy1Jzm+amWq4GiOfDUOQ6ZhbdyE//V+tnjxRbMHXmipxw6IXAnu2Sf6OsaEjhLdAXs42Btn/OIqDGddYKuBjhoXhwUkxLO/hFQVecLPIu5s7LO7btMrZEhaBUkVVeQXqKjLfLG0rOXDrav38ow66MhxafQyZ2ToYHVQIiIlE7O9jMObNPhg0XCmOe3evuGNgu8PLJg5w86j7eLfZsLCRzWW7e0Sde3I7n3dzNhoHl7yD4zvScUWqtAkbvxCh/UKkT5nI/dqiiybz6dDWTdIH26aY54cjnN9QMWiQunY+Jpq2EPlG7KqkZWmkG9RK+NQxwFesv4/0V8vhY9SYPR1sddqCBSOkL7QGjxA0aPXGNKGbs8x3n8PBzz5H7olCqdLmCUS9PK/200xM7a7ITKcnceGU9MH7QjyChYeRDLwlul3SpcpGp9qPl0jkCkvrrIVRnXITa9K0lemp1y0H89cj7bM5mD4uARNfW4YNqVngDd/kgfjnWolkWf/h3ZwlYNz0RVj3n3RopEqb2MkL8N4U6Ylya7z8Gtbn7n8ScZTfbfHvhXghXwjG2Gj+uxqkfZnOF1RT/u4JxAjho0XW1mXCflTv79/TrbTSI7Ypw+EvLLpgM5t24gO77zO7YOKQcPDx8AwFGfj0n/82++3vzFrNNNKFvWa/bTmN397Sg8LU43br3SRM2nZUuEEfoI4XK0m7jRW7bdSkYcMBvqBG2ytPNAaLhA0s8w6MiUIY3++KS/gpMREvmcalXeZdwzVEL18p8zftT7mZaUrF5zWV7rwVhxVsm2pX099j7OvgvX3r0HwXds4PBSHEjf3+rWs4tfkIkk27HElumvzVqa8v/DpW4npBKXQG6aajsQo3iwqQuSEThyxb5gj4OCIm21JrOoM84an1Gs6qe7kNrhNCYwOFmy2VmlykrTLf30PWxuFzcEVQhJKd7ktw5ZpJVzaGMhSmZ2H3P4qgs3aPl/fBbvLbllNKYos+Fy5iYWdTmbkZ6a6JA/TUHZ+coRKeyGqnrHXBZjqt4TeG7eSgQtggPtCyEdezspC61PS3j+KMRZpujMJk09+2nA7hWAM6PbCPMx8+SmRRPrBrmxqY/Td1Xu5Y13qNlbiSfA67FrO8YsNJnDpZKlUURGLEVH+xQsBCc4VFk6dVuVnivaKhYVFUIbb2cXVmV3DWia2Hiaz18o966MqFbs6S30/H7s1ncOa8VGnDB6SvNYB9W1aJy5tP4ozWCKfukYgbX/9g+m0yLBrMjrLdPeLu8e1WGvQH5yF3xbM4ksqfelcgoF+8+B6Xmy8OrdC1N9zvsbzXVFSQeOmtP5aIJd+kmz0xqVY1xbPwtjolDSwXgKjRVro2U8bjsb58mw3IP2s+WoaZ9lFR2jC6QrGFhcoHEcKChtLCmL8JVxInI3PJ5yi4yRKGTxS8TJr53bwotvjw7fGi8EpYFBw1FL35fTRDIXL2istspS8qEVoAKMJiMMlKMlP/PkYcE6JIg+pqiN1ZyOdf8uiNuKcbkDYPacR++buqra6jIfi4LpuXvIEp4yZiw0m+cm/0H1Yzao4lvSYNiSvnY/rEcZgjjIGjQPgAk3yzWjY6CDfz/YR/d5eODQf4DU8pX+g2FlEsnhpOp+Fzi5v3MWEhYouJC2l4e700tpBE6UNdntmvDKeFjoY9EBZRV3G8sTpDrIfX4fiPWfhOHidDoODD2TReXpHY5VqXLpjY1s/dXuINe4eiDcJrqziwAWk86flHYcwQIPg3USwV1h4Ximt75Ql7yPFchV79fBvUIrBfgLTfp4/gg/O3zPY70tXGR/iVoez3+B/FuGi17z6Room78Tp9Xaxd9e/ZvVbXZtyj/bsLFTWGwuIWHRerSagCIGQrZYU4KSxoOdXjRUg3s7Q/H5Iuoo4J46HwLmvlG5epOytqujqRbywaLmO/9H7yD2K/B4U7xPmkRXniOd4el/UoEbLzzggRukdoet6BYv5186QGuTmVZq09nFyb4kzsioghndgxvIyMz84g9W/p4nFZfAi7+TgVGstKmgpoL/FlKgT0auD6bxmFp+ud/Fxr3exX/SoEYS3YPaH9XOEj3NzVI++Hq9CaZlDsYsnJynnVISYIYSoW1/Zl4+A/jiJ5sRQH/5YljFNh2d87cm+I+V6Ql9i1aFsgd9/mqYSnxTY59QlBb2tjTDZah/rvx5ZUCBURTuE+Vo+T00BfcflV6Xi2F3J+48n2W65oaGr+Uld3uIbcb8ugM32836EjnJsgy9EWiM1ZOoU3RWdXdujuiyCerd4sRbHULZo92yR/J+AB3vLw7uzPy2unB6foUPRtQNqr1OhYOJ7BrqUnkMfPld6+CDQZ46TZw6IxabXWAxCOCJgQZn8L2FZWb1gYK3CTL1P4oYu1QQBVXgjpxo8Hi7PSOMT3q1bPPxqCj2+SU4rsL08iedU5oUWyUwRLA+K79wbeImzDGeG+pnNEJB7krdUttEpYNHllre1lu1qa8WGtxrCyVdPQ7dU1CHr4GTh7mLSccYmCq68YiEbTpxdKd6P4CntVqKF+dSV8e8S2scpyNSb9TWoF8vV6zB5l/XaDzsBLToAyfCjGCONKKBE8dCxeW7YFS0e1xilFg8QD0kDqw+Zi9Z9qxsfwHjQBC1b8ATG8vFCWie21GivlSJU8SkQ9vwATBok3T5pCmx6j5s5R5PML+g7B6HGXxkbOj36GXhPegUdIfzhU3z/yhkNACJyFbobYZY1JPL99IgulrETWsddzeGDCn6D0tdKqrBUpR83GemkshC1/m8RifRPz8Ed8H2nwZGUwYp9bgOUzxXFOtIe2w7ItSoN9kwJxbGY1JnyyGBOG1qwjfuZyLHwyGAqWCnL2bUImXy7YjrTTvNaBxe8pn7HtiIdaHgvGNxzxUxZj/XtTxXkuYw9O83tDfB2fLcdrT8firkPHjJiL9RuWY8GUeERF1KQf74jBCJFmDVWmzYimYvnm1Vj8p7GIlY8TowzuD7Wv9KiRtQdasRYdhD7DPWCMGCosuRvNZ2nIYhmDd8/hiJNuFudkfF2rhYy2XGqLHqjGi1Ie4B0Rj6mL1mPjlCixEofYJfmMRsybh4zB6lHBeFTZ1DXiBlQK0UuFsD7e6MrPqQ6OeKh7OD6Y9jQelbrCbpSyfJwRSp7hGDd1KF7prhLX0+b8GUahtlaDDncZKCX4ucXYsp3lg9u3YPm0ps4FNfj85ywWMt4I/1UcxvJaBEMOMhNrt01re+UJ+yQfyxHyFWXfkVjzVCgedXeU8jZHhAUFY+EL0XhJmBfphBHP2ee7dUeCdD3Q1ccXrzw1Bu8/XE+kdfJEuJ+CHVmO/3YoPpg4FF2d+CE+ga+stEwrkbom6/rQMLwcKG9X411k+5zL055PNN4cH16TtllJf9yIkXg5Sih44fjBpmkJ0ZJCOoULFTWGq6fws7ioxTmIBSxUCF0ycE7imDVVNYM4m3OAE7//ZdKdiJsHj1xGVInRrZF00GTxJ4ZdETahL/rFuNZc1Ckc4BkViAefFG/O2UscP4Ztd5gPPKXfdujE8oTxfTFqeFO0jGfHkF+eqXwQonaGsye7ML3LCb4464pw895z6AN4MMGDD9VTvzMluMyPd6dQDB7tKl7nuTgjiO1D3MMNu8nZ+owQs2ZX+D0g7QP7zy28E/q9MoCPK16Lm6eYkXXq0wme7Lg63+2JxOtlKLjKYrIiEINnhiI43Kn1r4nZNl3mdZtsm6IneIldOwvjF0VgxFOB4A0Emk4lbknXn6GPB9aMl2TpfLHYWott06CX2efkcQDYwVLFhGLYY51ZnKpCYbpWuEncfuhwKYenPA/0nhyB3lEsv2nqwrhcMQcvBA5k8Y//Kedlr/VGaBM81F9xQhzPxilSjRHjOzXvOA4qV3jK6Y6nV7U/HhzbFW4sPV8/xrZDfMeubao4fFUcXyUoHHFT/OHrXzP+iJhHhyHMJF+wPS83SQ+/ktIeK8sLaS/B32q+qRoZgdjx/ggINs/HnfxdeM95IpP7E80eFvakVW2l2M2iRyB6xUhx0FOJCHbtOaj7vXG24GwLi3Lkn+SB7YiQJ9Xora7J+/mYZtEvRSCA/Ubl+cvivar7WIvmHzYIYOl4cALbHn/HmvM2z3O6uIqtpNg28+zinqIrQ8baMyi8xc4BMf1YejWvrGnRsCitFPOIbiEYZDLmX+PZXrarVp1XBSFqtKrW0BdWOTij26R+iH99IIa/GACfZmwo1yEkJMSiE4RpCH37mbpru41a5K5/DlcuSfNc1zfR8/nh8KmzxioHpxbOrBkAs8s76DM1Rhxnoi6l6cj4eF6tAprz6K2IHqzCjYPv4+SOPdLSegyZi43zY6UbAEz2ZiS8VvupXOXTi/HZtDrGkSg3wOCqgIJ3nfTKOmlhHBZsno0YDz3S/167YmLqimSMDTN/T1zGjsY3CZi1Vlwm412KzR6itHhPzb6zmH2njlhjKETqyllYsqv2jaLgKcux/NlwKzdjrW9vmzRSj+Ozr8Ejxx/dZtSuBbZmRK+t+N/eKujOrsRTJ7ZLS2uT41FdKs5+jczNa00yZJZ441ag7yMBdV+Q8u7/vqgJWI8XdqA3C+/68K7U8o5IMybk79b1vqVJy5IxoboZkRZpCyZikUV3PHaZtrxm8GsrDJoU/O31ZUgziYJyXNYfWIJxC+pp7SVRjlqANX+KqUmjFvSnN+Pt1zfArNWlMh4L1ryGmLq+ZJZW+TpmY/nMOKGQZF0OEhNmofobIxZgizzgvjXl7POvs89Xt2KZiuXJY1HnkapiYfIhCxNr6W7gDzA82QPI/w6Kf74qLayPEpM+2IgJvSqhL1NC6ZiJVePmWIxPw/R6Des/iLeel8t5Wlk6lkyYDzmU5LCrj/VwrcAPKUXocb0T3h2vhEX21kSC8cEbwxAGDb5buhefSktrkz9XH/PfeOlZkwH665C760u8fkyaYTnrxCdGY1zPuvMQfUYSJu6Wznr+fbDxBXZ+KcvEB2tPWjyJL22vxXu/iX8SL/W19vtVMJRXQcHCr3qbrPy+uE+8e7YkvMPvKfcbJg7ozrs62yq2AVEG9sQHzwyCf53Z692OtR3kfL2hcaX7N6icPADGK3vgvHKytNC6MYu2YEa0FH8NWdjw1Bv2VyJbo5yEpRsnQH1LD70HW0/GKoybWyvl2VGeqCkf1Mda2eFOwnEYhnig47ZucDwsLWxCj474NV6JriujNY8fym7RWPOsuo79vsX22wUKk/hXHW/FudpKs/Dp5gx8V7uII3z30+ejxIG7LZil1butg7NIe5EsrbzD0or104UBRft34vW0surKcTn/MM8jRI+MGIPXoz2svtc402D8019R6VUGp9UPwMG0TG5VCGY9tAa/CTTg1M9P4lX+gFUrUD3WB3ExrshPlLpS6OyPYXzMGd5V1JdWauTggUFz1Qi4eg67pO6A/MbHYHDETZxZfxLZTTE4Orvoivh9P0Rai0yc2baxz77CB+Tm3YbVXj8fi2dQd4v3ugdhxPP8xmJtxpsVqHJzhpPpOvj4PFNCoeLdI9UaPFk6HmbvObBj0p8dkzpKp7crcP18Hg5/W4qb1ZVbjvAbq8Zgdd0pQ5d+VGzdJFGNZGH3YO1zUuXlc8gz9EBEN+vHpMHk/ZZmrTLZb/FYs3Jy8gEc4mN5yt+vPpa1w8p7TD/ERlkbOMyIipt34OzmWPN7HPvNYZNZ/LQaNYyoLGPXxDvPI/uMyZM4QZ3w4IQe8K3zmrgIhxrTCkyOA9KcdebrcHggFKOetHJjuOwyTmnc0buPyny/G6HOdbFQM4sfQezYTqr72N7MysLeRJ1U6dBI9aYpEzbGQXvCAioV+r2kRggf48gqi+MUHSoOVG8tj6wV5zlHBLMyU1SQld83VqDC4Axnl5p1iHkyu26uTu+185haaY1R/SoCsfVV0lrbXlvI+12HSk029n5RAtNWbfZsE2/ZUlelSa2wsDUvZ+pMD7dKUHBNiaCgSrN1yOFhHcunss/gh6/KTO5PtEBY2JxW6z4nVV4ugtbTH36V5mmxdjxsGfWt1+awuFtZguW3Bz/Nx5XqDMiO8kQjNPQYy+m9PpbnSdvyzRaIs3ZsU/37bcT1fcewd09j4qbt5wu7w8LyXFedhitRuCMThw7XlFmaPSyqsfg+o470YbYO29OFzWW7avWUny2PoeSOOhjxY/xxp7IKlYbbuPbLMaT/wrvGNaKqqgru7k3Xb6uVI7UJ+eu/xvlcLTuZS4sYo0GH0hMpyFwxzbyShrv4Ps6uWolzJwqhN/lOm3AgESnCIMCMXoPUpK/Fvy3ov3kX736WbtY9kKGsEFn/WYKJKzObpqBosyyse+UlLPlPFgrLTA6sQY/Ck0lYMnWK1UoaTrP+Lcz/LA0abVsLkOa1+0Km0P2ZqvtoTK9nAO6K3e/j+O4slLLjels+w7LXiuJ8nN/2PjLMKmk4HSpSJyPzsxQUFLLCiPmbre7rpFQUit3IQnsyBYlNUUlTDzltvDTdvJLGHvpd8/HyWxuQdkELg8m1rkGrEcaImWxZScPpUzD/5TlYtcsibVTxtJGCVWvMm5npdy3BlLdWsbyggXnU7o+wZG0Ksor0ZtuEci00LE9ZMt20kobbhCUfJiKd74Pp7wtplW3P3JetV9JwGfvgyL5zJ2Q4jCbd7dVNjw0/ZLH/lVB6sPA+kli7koY7vQxvLElCjmkewLd/7wbMmZQEy+6aiC0M2Lh9G97/byYultwS8o6m9t2undiYcQl6+WktowH6K2eR/K+tWHG6rqEqbaO/fBbTP/0vvj9dDD0rcLQ9Q2EcNkA4vI5H1oiL6pH04ediCz1OEQJ1U4+Vpt+APbw84cHSHrQ4us1qymuj5Qn7fL/7v3j7qwM4c6UM8tAXMFYJcfH7r9LxlbSI01/IwPvbWJrQy3GpCoYbxTizexte+vpMw/e7QouLB37A25/WUUnDFZ3E6xv3mW9XEzlzbC+m/8vit6vT3zeYblJJc89wn4aR/Kmym6fwQytV0nBiH+3lKBd7WxCe9OaXRxVldcSOzq4QLr100pN4jBMfvIvN3WqqPpGEAYOPsAvwAmjZdlRHp9vlrDx1Dnv/08gL1PMFSNuahys6OV3wG/ylyNt5FDs2X671QJrtjNBmXhGfCmRps+Imvxlrkig6OsMzQupPv/qqrwpXEk9g97Y8FJqMvVIf3Q8nsXvnZejkQvNtHQr3nUDqZ9dw7WZbPH/Upk0+if3p13BT3gdjJXRFBchYl45fTkqFaFNFJdAUiftmNLDjyo5tzbFicdejEyKfjcKgaJNWtQXXsJ8PSHzSZLygVmY8nodUIQ7K+83j9hnsXp2PAq1pNxmNJ64r9+7xqqAIe1edwKnzZaioDg8Wf69dxamtR7C7qSpp2hqdDsdWHsXB9Ku4LrXQaFpV0Hx5DBnZZTXXqkJlbS72rzqK401ww5fT/ZiN3RvOIY9dJzXLNXF2ETLSL7M8ucLk92vyzl0bzCtpOHu2qTIjD7vWZeGMaTzk62Hx8EzSOeSYHi878nKeHvbuuIzrcl7A8hwhLNZlI/tS7RiuSz2LNOFcZJJ+pHRxJulYrUoartnDwua0asSVrcfN4qAwrpdwvmBheo8kbJvDQipL7N9nmraNMN4S933XStNKmvtbs8dZOxQmHsUhni/fNCkHSmWEzC94GbHxpbVWw9Lw/h1FLJ06IWC0eZml5cKCpY917NzUDGUjm8t21XhelWmRZu/idBFOF/K4wNL29ULknWjaMpQpKy1qCGkj7GhRA6gwccCXeClUAd3pD/HCqZRaNaHEBnKLGounv0kTG3EIhl91ZhcB30HxWUNa1bQ1LdGihrQLtrSo6boJldOGwqg7AsXfnkZDhiOJX7gFrw3iT4nnIHHcLKy75+6o26a5W9Q0q3pbmpH62dKiRo1ZD76P33RRIP/Qy5iSny8tJ+2CygeDZ0XAj5V2z2w4iewCabnEWd0VD40NYqXjqpqWTKRB5Kc0K89nYfeXZeY3I12cETrhAfQNcgRMWnwRQgi5N6hG90XcQKUwbl7aj81RcUoIaU/u3BGrTvgrn+SWNC3UooaQe5kOG4+nIJ9dTakiJ2OOR72NHglpG1JXo2Mpy/S7j0bVwOHSQkLuYw7TYHxmKIyoQMfkV+9eScPHp5q5HFOFShrAcDoNm9p5JQ0hDdG7yyv4dRcFcG0PVlMlTbvj0Fca5LmoEHkWlTRcRdY1XBGa2xDbuCIwgrfnqkRBukUlDXerAvmn5aZhhBBC7i1O8Avl1wxVuHGFKmkIIW0LVdSQ9qdyJf5+OAeGDt4Y8sj7mF5np4uEtBHGtXDYsg8ORmfcHvMxjF2F0dMJuU8Nh/GFv6DShxVSMtbA8WT9HfXxsZWSNyzHa4+Hi2ORFKfhk3mb773uqQhpYiqPd/B/Q8KhuFOI/+57H83cKyppTf4BiOSDk5uMjSIOdB2OMN7jnOEKCs+Iy4ktnBD0UGd4mww0Lg/OPji2kzB7PbuMWtMQQkgbpRoehn7DVfCUn99VOMF3TE/05lk4nRsJIW0QdX1G2i65ixxpVnYuMQQjV0szdVLh173W4o3e3uwKKg3/74d3UNcQIfeDhgwSb06P9L+Pw/xw6vqsRQ38AZVP9oDx1jkoPhyJDk0zFEkLkLo+k+ZkZfuD8MB8k77byX2oCpu+KsBQT2lWVk/XZ3ceO47KWJbzl+yD0/Ln0OEuXdnK+Rsf1ypr3yYsWZmKphq+oq2Tuz4zdw5O80e2/SdxqOszm1gP63q6Pus4Df8Y/Qx6KAw4t/9N/P4S9XnVLrl4oN8fIhHiVk+KN1agYMdxZGTQU8O2UA1X45GhHvXmpcZrefhpTRHk4V8arCGDHVto6YG2CSGkPZAH0q+tEoXJmThE50ZCSANQ12eENJoO/z29EBvztDh3djsOSksJadMOT0bHHzVwPP7tPVRJQ0jT6nDqBByKG1ZJw6UuGIeEhAQ8NXE65txHlTSE1Ov2z8i4qqNKmvbuVhmOrTxWexBcPtDpLT20J89h76qjVEljB92eLPzwhTjIbs1A44yxUhpQ+ih2/MOOShpCCCEtRpd6ThjEvPZg40eokoYQ0iZRixpCCCGEEEIIIYQQQgghhBAT1KKGEEIIIYQQQgghhBBCCCHkPkAVNYQQQgghhBBCCCGEEEIIIa3ErKImLCwMLi4u0ty9qT3sA0dhQQghhBBCCCGEEEIIIYS0f9SihhBCCCGEEEIIIYQQQgghpJVQRQ0hhBBCCCGEEEIIIYQQQkgroYoaQgghhBBCCCGEEEIIIYSQVkIVNYQQQgghhBBCCCGEEEIIIa2EKmoIIYQQQgghhBBCCCGEEEJaSYeQkJA70t8ICwvDpUuXcOvWLWnJvac97ANHYdFIATMR/ORw+Pmp4FRdHanD+XXPouiSNHs/GrEAW/4cA6U0K9Ij/e/jMH+3NNuEnB/+DL3jAuBUdhRZa97CjXs7WTa96WW4MLZUmqlxLjEEI1dLM/e5gOeHYFB3oDD5AA5lSAvvc/fDMZH30cz1PKSuKGI5eR1cfDD4jQj4sT9vHj6K3TsqxOWk5bmo0HuqGmHulSj+MQv7992bYeE9pj9io5zZX1eRsTgXBUZxeS3RoRiT4C/N1KB8q3Gs5gPns5D0ZZk0Q1pEoD/ipoRCdbc8mJBGUI2MxCODvQBtHn5aw+JZXfltO+Lg74XeT3RFUGel2fXqmfUnkX1ZmpU18Lza1vNN1dAIPPQrHzjduIiD6wpQTNeG7ZgzQqeo0TfQCbrjWfhpmw6tn6wbv03t+jrManm2CIcW5aFQmqtTOyn7E1KXO3fEqhP+yiej0YiqqqrqV3d3d+H9pkAtakj70/tDRE99AkEBppU0pOUNh9eAADizMHDw6o9OvaXFpMUFvTAEY17xh0qaFwphc4cg7jF+A7I21ei+7P1QBEjzwk0a9vkxz3tICwhpg27drr7YYuWl+4JqSFcM/v0A9IuWFjQ5B/g+GobY1yIRESgtagi1L8I8eebvDN8BXjV5zz2m0lAp/cUK4K0ep+wMC0IIafOcEaj2ggM/bXQKRa8oaXF7pu6KkVMiEepvWklTj3ZxXmXhPMBHvDb07IpQtbS4Ds1fxiHNKtALoYH8WtMBqgd8hQepWl1b3Kb2olnzKCoDk/tLQ4oFhNxDYuAXpxYKgPqz25Gx5FnsXzhamu7z1jTc7vkYl5CABGFagvRmfbhqD0qPFKLCCBhLj+LaKWkxqbHaA93iQ6qnf+dIy5uUM9y82EtpRfVTsM4eYgWN7qr1J11UPkqgrObz8HJmv8I+X0xPxpCWxJ8qPYCkRdLUgCe55ZvplRW3xT/aOVV4EPw6OUEhzTc9J3j36gxvVUdpvoGyipF7nWf+FSg+UnrXcGurjFXSHwYj6o1RGXk18ZRNh85Ly5uUnWFxDyv80iT9JxdJSwkh7U8FLmeVCg9ZGK/l4XSmtLjdckLYr4LY9aoRN7PPIHWpSV63yEprGq6B59W2nW+ycD5SIl4bXr+IvCxpcR2av4xDmtXlUuRd5teORuiOF+OKuLR1tcVtakvMyrNZd29FY6pZy/73XxmY3N+oooa0M/3h5steDFnI+2olKm7dq7eH2oeKnycj493ROPgxdXvWehzg5MReTJoYODnzQo4RVVbvPLLP8yuiOzWfhwtbxl6qWv+RckLqUQHdDemvMvkOO2kV7Nx7akU6khYfvae7PrhZohf/KK8AncIIIaT56H44g+TFB5D8j/uh2zNX+HRiL4YinNhaCl1DTjDt5Lyq25eNXTycV1C3Z+1fBfLWH0XSonSktoluz7i2uE3tRDvJowhpC6iihrQvXULE8Vdu6vgDsIQQOMHNjd+4lrvwAdy82ALchK5YnDfnxLuYZVdSlewTIjfewoYpL6n5DUIIIYQQQoiNAl3FboHKK3CTrlcJIYQQYqJDSEiIOCIOQwPYtx0UFnbq8g76TI2Be2k6Mj6eh3rr8h1i4fHYi+jaPwQeUpvq27e0KDm0Dfmpm3DbrOA8HP6vvonuXjk4tXAmygJmotvYeHT2UaCjA1BZnIOcrW+i9IqdLXgeX4wtM6OghAZJf5iOVRek5dWUmPTBRkzopYB273xMXJwuLvaNwdjfjUX8IDWCvaWdqDJAz7Znz+fvYlWqVlxmVRwWbJ6NGA890v8+DvN3S4sba8BKPDgmXJqRScdNmjPl8cIO9A7Lx+l3X4d+wDsIf0QND3b14sCOf/nFdJzbOg/6RjeM8kbM05MwdvRgqLt4Q+EoLjWUFSJn7wa8uzIVZkdq2nIkPx0OzbZxeP3Yi1g4bTjU/mJlBfQapP/7I8zfatJef8QCbPlzDHBoGcZ9qcTc155BTFdpPQYtcnaswlv/SIP0bHadlqzKx2/ZoTuXGIKRq6WFdrI6mGgddOlHcQg9EBfTwN5km2JQUk9XBA8PQXiEB1QK/syAEZXXriF7zwXknqlpDSHuRwVyvzyKHIU/okYHw0/FDqyxCjcLNMhILILWMn4onOA9yA8R/TrD19tZ6PMcxkrorl5B9vaLKDDrCcIZEa/0R2SHfKQuvwKn4d3Qd1AnePJtYt+5npOLw1tLa19IOzjC91fdoB7gA08XKUJZ4Mc1dadJLuSpRNjjIYjo5iH2R85//4IGWf+5iuLr4kcsucV0RfSDfvD0cBKfrGDfqYST8P2mGMTSObwTwof5IchfBWeemfFwKCtDwf48nEqvMHvSTAwLcVB1bTTbrocD4F1fWEgDUDvwgf1/7oiwJ2v23Wgow8Xd53DssPXKP3FddQyo21g2xQ879lsaiLNwBwuffC/0/U0IQjq7svUYYdRpkZ18HtnZVlr8qFiaeJQdo0gPuNUZFlJ89RRm6lUrfjR4vz0waK66ZoyqOlmGj/Vtq5UOLDgFd0JkfJB0jNiCpgwLiXNkZ/Qe5g8/ecBmIe0VIPuHIhQ2Q88w4nY2RRq1NywYByf4PRqMyCgpP2MxyHhLhytH8nH8R73Q9UyjNSjOSuxNFzJ5gNu7nH8cgjwQHhuIIJbXyOcWq/vdLRAjXgiBm+EyDi7NxxUrx8Pv2UEYHOmI6/uOYO8e+x9UaPA2cTbnm3aew2whbZOKH/utFQhKCEWkHOa3dchn23TCMrwlwjlsqJRO+X7rypC/z0r8MOEW5Y/eDwXCT86nbpdDeyYfGclsPwziZ2S2n8Osp0vVY32EMpC19/iA771+zcJPXgfPb64WInvXZWguWImzcvlADge+TVbKN41he75py35L+c71PKSuKEJlJCt7PRYEX14OuUte21Dyeq2re+Bqm8PChjzK3vOLXeQ0JR3jun/WvvNqtQbmm5w9abXB5O0wYy2cG1HG4RpYzhbDmq1/8WW4TOYDyzvDeD0fv6y6jIrBYYgd3pltSTnyd5zEsQzzeNXc5Qmbzhf2ptVmzqPkPMdMnXHQ/nOYLWFh2zbVsPU6jOdRvZ+QyzdsQT3nL3vYFj8aSy6D1p0n25tHNSwvb0QZmJBmcOeOWHXCX/lkNBpRVVVV/eru7i683xSE/IaQexm/0f/g29LEK2n4Qq8YRMvL5OmFacLnBappCH19HnoPrqmk4Tq6eMPv4Rcx4PfzhHFuanOCMu4zDHz5CQT6ipU0wlLfcPSa8j48XMR5m/0nEUeF1g3BiBoTLCwyo3wOMb34hmqQ9qVUScPEzZyNqaOiaippOEcFlP5qjJm9AgtGSZULbV4AAqZ8hugENbx4JQ1fxP5zDYnBA1PeYUWARhrxR8yeFo+o4JpKGk7hEQD147OxYn682BLLgv+Q5fjsr2NqKmk4ZTBipizEghHSvAllz99i/XtTEdvNZD0Kb4Q/+Re8N81KuN6nnCKCMGxGP0T18ZIKmZwDnDqxAvezwVYKZLfhFh2BuGdDxUoajl1kuAWHInaSf63BClVxPdlFVlf4dZJu8nAOTlD5ByF6Sh+w1dfm4YO+U6IQO7SzdNHCsO94RkRi2AQPi5OlIwImROFB/tk6KmlqCfJn+9wXvbtLF48c//3uYXhwhpVtcnBG6JQBGMEuuLzliwOOfaf6+40V6I+HJvRAGCv0ize4OBYOHl4IfawfYh+zlvI8EDq5L0aMZttlGRaTa4cF59YjBA9ON993B4UHQkZHYVB0U+1Mw9kVP+zYb++BERgxlQ8ULF2ssWProOqEyPG9ag+EyePHLDFNiDeTuJqwGDmeHTtpqb3s2+/mpRqpxqhJPUyOEVO9Tf0RHW0tfdkWFs5DIzDy2TB2iE0GbBbSXigGjbMedvc8lQeiX+uPwTEm+RmPfy4eCBjaFyNfZvstL7aXnXHWpnRhMw8MmKxGZIT5uUXe7ziWl1dv04Vi5F1jrwp/hFgbuNzFB6ERLH4ZryH3l8a0JrVhm0zYnG/adA6zk4sX+k3vh2jTMO+oQggL74d+ZbkX7Dz5vHQOk9OpENY8fvTHqOet7Dfb3uBJ7DtjQhFgmk91dIV3n0gMjrM4J9l1DrORNOC72Tp4fsPyqKgXrJRX2Lk74vcDxPKBSXiL5ZsBGNYE22RfvmkPJ/iN7YtRvOwll0Puct5rVraGhV15lO3n+obiN4rHzJUmXknDF3qGIk5eJk8sbbQsO9JqW2RrOZvto99TfYRKGmHOMwQRowMxeGRn8R6AgytCHg0C71Fd1vzlCfvOFzal1RbIo+xi4zms2cPCjuswp+hQjDIr3zDS+WvELHZea/RG2Rs/2hhb83JC7kOOnp6e/yf9DW9vb9y4cQO3b9+7g/C2h33gKCwazrnfC+jsLc3UR5uFi8eOsD9C4PP8m+jGSl7Gshyc2fgWzm1fiYt7f8LV0h5QRnSGizIESoczuHr+kvhddIdqyMPwdvGEVzcVOpSy722eh3PbluNiZhU6RPaHh9IHHcp/Qommjkfj63UJeV0ewRM9PeHp2gE/JaWbtT5RTn4J09U+gGYvln5R817o0EcRrtuPzf9chqWLV+CfGzci+WAxVH0HoIenCkG+HbFxB99na0Ix/NlYBDlX4tK+LUhtqsGPLyfj4o9fSJMrOv6qNyssaXH1x2SrLZzE8HOEi7sCd6rD43Nc0nSHR98gOLt2xm3NJtyor3HQ3XSPxaPheuzftAbLlr2HFWs3YmPKfhSrHsCAcE+ounZGx43/RfWRGpiAiex4O6pUUECPnP98gjlzF2LDD9fR/eEYBLkq0FlVjs3fS61qug/H+KFBUDiroHI0oPDARvztf+fgb9+chWdULHp6K+DjqcBP2w5YbVUkG/X4dfRlwVyS5YkNh6WFdtIdL8DZvWwqdkR3tTuuJh9A6ld8WTE69A9Ap6qLSFuShWPsM3k5VTDkXBU/f+wWOg/2QVX6Uez87IKwTN+tKwK9riFz6XEc2sM+c7wBT/HVhV34DfhdGFjUROXlPKRvzMbRlIs4m3YZ58+XwcGvI/QZN6pbH6ke6Iou7PipOrvCsawIGZuycPg/F3HuohF+fTzh4uYK48VClnalLzCKEJaOyi7hyLYcnPjvRZxh+3AuowQ3g3wQ4OUKX+UNnD0p70NHdBocAF8XBdzcHcVt+tcZHN1ZgAu3nBASroKTtwNuppegTM7K1MHsQsITjrdKcGZbFg4m5gvruFB8m10geMHNQYczn2bgCMsbBA4q9JvWE/6OehTsOo1fEvNwOpUdx/QrKHFyhn9XT/gFG3Dh0E3IzxCpRvXC4EhXPkgGzmxn6/iWreMnvh/FqOwWgM7uLIyzC3DJplEeLbi7wa/LTZxLykXmfy+I23TgMooMLujSXQm3wA4o/bnUIiw6wpWlVVgLC1eLsHBXITTaCwoXV7h1rERx+mmkfXkeWfuuQN/FF4Hst1RubP1Hy1HdtFcirsuAaxlXUdJUT7BKbIsfdux3oBd6RqjQUekKpzs8zE/h568u4MzBEnRQd0YnV2e4O5Qg96wcoVzRm12w8HsFpvHv7IEruNqhI/yDVHD29YGi5BKKrlah5CB7j6dVNpUF820Tn+oT03fNZBk3Gr7fFbhU/TvFuBPF0wd/Wi0D+5NN12EZNubbdsnVC6FBChjYhvA8ppZugXg4wY/lsSZxg8XBcydKUennyc4LzvDoxuLg/uvQSxHE5rBgxzby2VD4OOmQl3gC+6R0dDa9EEUlt+HqXYWrmTfRBA85mhG3swnSqF1h4YCgCQ+gpy+7+DU5RjyPvcSKJ949POCq9IK34xXk59n76KUtcVb6is3pwoL0fZQW13MOcobvAyw9/JCDw9tZPsvPV2y/L169Ax/+RL2PK6pOs2Ml9OtpxHVHV0SEKaFyKce5TPN8yGFgEPqHu6Hy7HlkHGtMDLFlmxib8007zmG2krfJ3R2eTgYUHzojbtNP7Hzh5oluXZzhGsCCxiStOv+qJ4ZFKc3P8yyuns/Tw7W7D7wCOpnHD0YVr8aDvdh5z2h+ruTnvSvld6DqoMelPJO8xK5zmPV0qQj3E/Ir8/ccEDymF4I8q3DlxxP4eYt07mbruKgph2OQE26ks32WPs35Ph2F/sHseGefxf4vcnD8Bzm8K+He3Rs+3dxw+1QxtOXSF2xld75py347o8sjnVm68EDnzh1RcfkCDklheO7sLXiygqqSpWPLspctqsucZtMNePD1siN6aa/lQNS2hoXteZTt5xfbyOFwV2Z5nI3nVUsNyDftSas2Kyyt3of6w9nOMo6N5WwxLJTw7Gxkv52B1Bwn9OyhhDLQEwotb51yEYj2g5dLB+jPyefXlihP2Hi+sCOtNnsexVRfg/JJx45tvXHQnnOY7WFh2zaxOGLrdVinTnjotyFQVkjXhtWfL4GukwqB/t4sf76OnFMtWJ5oNCl+WU2rMlvzKFvycnuvRwhpGXLLGnlydm66iu466oMJuXeUfTEa+xdK07p0CGNJ867P5GXy9MVa4fPweg5+IezVkI+z62ai9GK+uNyYj4qjf8Lp5BzwcoBH3yfZ6am2G0fX4sjH7Hv5OeKC0k24clY8Ozh7WHb51XCaz9KQxc/dwYMwtpu4TBSMFwfx3zUg6+fPoREXClIXT8eUvyxD4t6c6q67tNkpWPbvTPEE5+uPWGFp22csSUcmP65CeOhgzH0fBULQKODkxV8bYfciTH/pDSz7Jg058rgsxTlI+XATMoWaEx/4DxOWWtAi/cPJmLUyBRp2QPWaJCzZK4aAQuUjvJozIOebOZiyYDPS+XqK07HqOyks2Oftjx32c/Bkx48VdG5WX1g6w50/rFdx22rFGXxcIIxgUz2mjTPc+PE3ss83QS+GqqFBCOANwAqysXt9EYqvSTcKjUZUaspwan0BrohLzGnzsXd1HgoKxM8bz19GrhAU0vaZ0O05h7Rvr0FbZKzursGoK4dmV4FYyPR1FfbRUuX5LHGbpMRUkX4ZeUL8cIaL6cW1i4PwxNLNrIvIzqqsXkdFVhGystiVDbtg9DR5HMghJgAhLiw6/JiFjPRyVMpl9FuVKN6Zg1MF7O9OPmDXhxIVwqLYBQTb2jObs8V1yIdJx8KyqXqTvHwVB9ddhCanomabDEZc36dBLq9vduAXseJiM/widmXDwkJUyS6EM7F/pw4VfD2GShT8eFkcA0nlZDUsmpO98cPm/Tay8NtwgoV5hRh+t8px5gB/hJ99w8PkmTd1ZwTz4L6ej7TPauIfP07aPbn45TDfKkeERDXuKVu797uZ+A4MEtanO3yyJm4wRq0euV9k4QyPg4o6Wjs0OCwc0bGj+FflzZp0hFtVuJ55GQc3XBX3vT3x9EZoMCveG64i49OaY8R3Xpd5EWk7iliKZB/r48NyGjs1Js42NF3YpQzHVuUiO5Pls3I+yVZyM6sA2UKXsm5QmeTNxswSscuzYB8EmbWIdkCQmo/0zdJHemNjiG3bVMP2fLPB5zB7sbDL3Xq8ZpvYflzfcU5Kqz7wrS67uiK8P0uINwtwkMcP+TzPVGpKkZF0iZU/HBEYaRIDHTzQK5rPlyN3M48fNedKft7T7svHoT0WpRZ7z2EN1oE3UhcY2Q6bruNmzjUWrvnm5RUXH4RFsjh8ORd7vyrFdTnqCOFdhINpPJ57ILCv/S1eGpVv2qwSV344il0mZTVj0TXk8zJLnef75mJjWDQmj7K5jNMwhV8eQNIiaVqfJ557eJdV8jJ5amzXwjaxI622QbaXsyUFecjkXZtd0ktlAXZ++qYIOgO75qnVkLIlyhP2ny8alFZbII9qjIafw5o7LGy/DvMcEgRvhwrkbbP8fDkKvspBLjt5O3Vn50lxsZ3sjR9tiY15OSH3KaqoIfefsBDw8srtc3tQauUsbjxyFMX85Orlw4oFlnQoPvS1UJFjqmLHs0Jl0Mkde6QldtBvQHouP1sFIOo3Jt1kdXsCUXxWn4U9/6p5VkygjMKEOcuxfvO3SE5Orpn+HCN25cXOhI297dFSruybZ9Gvqg7l9o75U4sSUePnYvmnW/DtdpPjlMzH6OHvK/jwDbXl7sH8XebHXH+2UHrKw4qyTHy91mTsGm6Xpo4+XVuGmxe/+1RZU6Dr7Mouy5jScvGGjyUfZyHeG6sDwxkqd/Zyo47P28QRvqG84FuB3B9LhJuFDVX4y2Vclwtzkut1xQ8Htp7hIYidNQAJpt1JyF1NsDNf7ZOfjgV3mcU2VeC6eP/Q3C2j8Dk3dVdEqGuawzur/aFW86NbBYNJId4nSLxC8h0+yLx7C2GKQZTQHYM7PLoIHwMClfDhhVhtMQqaub9d3r9z9NS+iJ9juk0mfQ1LF0KmCn9hF7FmabWesOCuF+C0RR/fKNDX27qsWdkVP+zY7wsaZAsXySaqbwbUUAW7C/m09viVWr/P6TKKwe+9wUcafNhedu5383CGdxd+I6AUeb9YqzKuQEEWP1IOUHWufSZueFiwdJ3Jl6sQ8UIMRk3tijCWRp2ki8R2Kcwd/H5GZc4VFFg5JMYMqXLC0/741Kg428B0YS+hf/jJaox6M6YmjrNJ7JveAY6medqtEuQJ4+J0QuhDJoWATmye58vXi5Bfa8xA29m0TTKb800bzmH2ulGM/FrjCLF1CBHK5Gagpxu8ecC7BSHW7NwiTc93FcoZTr5ieUMQ6YVOPAMquIjTNrTwtucc1nBVKEjnFZuOCHiM5ZszwhARo4RbXd0cd1fBm+9DYA/Em+6vNCWM5JV/LP10Ekphdmhcvmm7EuTvr11Skyscao0P0qxsC4vG5FE2n+vvZfak1TbI5nK2pPC4xbUIK3Tn1FnubpnyhF3ni4am1WbPoxrDlnNYM4eFzddhjvDuyo+ZM0LH1z6uY+b2QxivYVew/MaystBG9sWPtsTG8yoh96mWuyYnpI1w9hMHMyzX1XX7/BzKW+kO4uYfsoRKgIDo5yA/DBc8Jgq8nkZ7JBFJ4iJJHOZ+shiThoUjwHSgHVJL3Jw1WDw5FuH+SrMxatotPkipVHCLG8ir7FSInCIV5l4OhVBG7K6WCnehCAAfrE96f7T4+GlAgjQ/V40gfqao7ke7TyPGEegoFaJNKo6anDPCXuZ9Lwea9ynclLIKcEJTJTyZFjm25qb3qLGh8GUFzcrzZ5FlUl/XsaHj2FiqqzKtiaiGq2v379zutUD8sJHKV7xNVFFmeQNUcrUcjeiBQtLW9tsZnkJGVIFbwt2y2m6W1FklbhPdzpPYvS0f/D6bs38Qeo/th/i/iBf2QZZjG7cDqs7imGoVuto3bUQV0AlNj+3XMnHWdg4PhNTu9/wurqQXCPmsZ6QXi5Ui536+wnny+smSRlcg2bNN95qbpRZnKjd2rpf+bDCppSoMt6tb/N1NS5zDKjPysHvDOeRr78DBuzMiH+uLEW/ECDeXwiItzu3yPjSblss32yJbwqKt5lFtjj1ptQ2yu5xtmdncJf9p7vJEs58vmj2PajktUrZr8HWYfH3bvNpLecKm8yoh96n2ecVASD0qikuEV9c624b2gGvjepix338ScZR3meXfC/HRfEEwxkbzahoN0r5M5wuqKX/3BGKE9rNaZG1dhunjEpCQIE1/T6+71cf9RjkJTwwR20trTyZi2fRxNccpYQnSW+2x/vtZh5pBFptaH39E8MdyjTrkJR1F8mKT7iTkriYaS+WJoCBHVF67Bm1ZpXRRZ2SrLEXenmPY/aXlE2Ei3sd29bbUmg7hmEVjLN69TbM9weigQtggPjinEdezspC61HRbjordp7RHLRE/bKSTbqw5e9RxcSK3gmuMNrffFbghd2dRx9OFbj5ihUNTuHn8Mg4uS0fysmPYv68AWunCPnpKYyqe2ybdNfH2ozPLP6yTWkk2QovEWZs5ITQ2UBgEulKTi7RVJnGcTYfqaqVxoRh5/IndToEIF7ruckZIH1YINF5D7i91VXY1lJ3bdI/x9OM3xY2osmxubq1bJ9NpzTWWE1hoaOGgqc9hDh2kP2qr1PDuWA4haekRpO3MQ6F0c6n3s1GIfsDK9p7PMtmW2lNKor05bjPkm/Xsd1vU0LBom3lUG2ZPWm2DbC5n26H5yhMteL5otjyqZTV72c7m6zAdzqy3fkzF6Qzy7L6+al/lCZvPq4TcZygVkPtPSYlQ2OzYYzDcraSAjoNiwMfgxZX8Zn2a3bp0bDjAO0IOQNToGKDbWER1AQyn0/C5RfcbMWEhEB7euJCGt9eLY6jIlD73TpdnzW5IOEKEA6VB2v+tQ4r5gbLe5dm97nKRdMEl3awwXMZ+qSCX/IPYhrxwh1y4Y4UjlOGQ9L5Y0CvFiRXS+19eFNLLzcNHpc+fRLbd3XFVQHuJP92oRFB081wiq4LE7i6gKcCJTGkMBBkrcDdFcHs+0hV+DnrkbT+HtOVHkCwcF36hcAYn9pXXqqTRFogDBHUKF5/wvKubt8Xf8FTC0yKPcuoTgt5mY1jZyV9q1o9ryP22DDrTFk4OHeHcTjOQlogftrpZKh58b7W17jbZZg0Un+6vrK97qLuU5hq/301duVqJm0KrDi8ED7CydgdnBKt5eqlCiabpbg/xvsKL91xEGruw33+S/a6DCkEPtOUOXay5S1iUVAh5tlO4D8unxEWmnFh8EpZfvVE9tp2tmiTONjlX+Ai9trC8+Yer0JrtnCOc6uxWoxJ5Gfy86IqAPuy81M0HwWzjK7MLUdDolp/2btM9ROWDIKG3Xi2Ks4UlrAyiRwnvqtSTxUGxJ527y5XiY7CvOLbI3TTmHGaZLoL8ER3dgAqOW5XQphfh0KpD2PUjf+jLieUfJhsr70OQl9W013iNzDft3e+26C5h0TbzqDbInrTaGu6SnmwuZzeBpi9PtMD5otnzqNbR5GFh83WYfH2rQkCvu5eo7dNOyxN3O6/W0owPexLShlA0J/ef3BRc4uU5hRrq378Hd98QcblDCJwHr4R6dAg6woDCg5tqjUXTEjSfpSGLFZq9ew5H3G+iEMAHqM/4ulYLGW251HdJoBovDhJbjHhHxGPqovXYOCVKrMQh7EDpIR4pf6gnx0A4Ur7hiJ+yGOs3TEVUu36kzgFOvLxYXgH5HoabBy+4GlFlMd6LiH1eiDgm3Wp4iU8TVVbW1xlAwxVniIMhu0X1Rdx4L3ia1JY6BXug95Qg+Enz9qiskFKtvxeCpIEnHVSuCEiIwKhng2x8Mso6Vy8eaVzhF62Cm6cjnO9yXVhxohhadvicItUYMb4TvIWO+OtxvQyX+X1DRSCiJ3jBmYeJwgm+j0VgxFOBcGuKM7d8EQIvBA6UusJSOMAzKhAPvtYboS05qnwLaon4YSvj0Sso5OmxUygeeaETPOX4JIV57EC+QIfcX2rfTqooE2/GBTwciiChj0Lr7N/vStwSVqtE6OOB8JW+23hGFGRKg9o/2AeDhtb0Le7grULE5D6I4HfRrmuQ25gnYAP98eDLIYhgGb1pOuX7rvISO/KuqmqavK35NTAszheLT2yy/GPQy+xzcn7DrmxVMaEY9lhndhlchcJ0rVChY4/GxNnmY4RBOK+xvPkBV/FCnv3nFt4J/V4ZAJa11cmYXoh89l23Pv7oHeMPN5RDk94U227/NrVJTizd+DtUXzw6BXsh+qVw4YZfZfYVk4otHS7l8NTNzumTI9Cbpb+7dgtzvRT5fPB2h06ImhaBCLVzzXdcnOA9NASDhpvkVHacw6rzyyGB8JRuarmxNDFiUmitm3EiDxZOPdB7qBJupk92se1x95U2zvRCgZ27C66yfWBpb/DMUASHs+2y+rv2si/ftH2/2yLbwqJt5lFtkR1ptQU1tIxjcznbHs1enmiB80Wz51EtpLnDwo7rsOKsK2LePPQBPJjgUZPnNJn2Up6w8bxarbmuRwhpmzqEhITckf5GWFgYLl26hFu3Gv0IWatpD/vAUVjYqcs76DM1Bu6l6cj4eF7dNyG6ss9NZp+ro3CiP7UJWVs/NzlPDIf/q2+iu5cO59c9i6JL0uJmocSkDzZiQq9K6MuUUDpmYtW4ORbj0zC9XsP6D+JhtQO3cgMMrgooytKxZMJ8pEqL4+Zvwewh9T89pz+wBOMWyN+wnccLO9A7TJqpQ2HSaOQdEf+WP2+6TOY8eiuiB6usvtdwary2biniLQaQFLHjZGDHSaFH+t/HYf5uafG05Uh+OhzITUTCK+ukhZIRC7DlzzFQmr4nL7M43qKpWJ48FuFW3zO3ZFU+fstWey4xBCNXSwsbhY89o0bA1XPYJXVb4Dc+BoMjbuLMemstY5wR8Up/RLpexv6/5YP3wuc2sg9GPMjCIPlAkw0cq3qsD+Ji6irBFuGQ0MpHFPC8OECitfXLv2P2nsoHg2dFWH9S7GYFKt2c4cS7eFhRxC5POWmfPXlz9drHRFy/+XsOD4Ri1JP+1lshGKtQob2CU9/ko6BIWsaofhWB2Id9rH+H490QfFnTD1+d6yi7jFMad/Tu09gwcUTwZFawt3bha6xAhcEZzi7m+21zWPCxkvhA9WbHWybFTavvWT/uTcLm+GHHfkeHYkyCf60wFcjHxOI9J/adEew71uNHJYp/Pon9P1o5o7HfGzbZ+s02s22yY79ldcd3i/CR902atcpsHY7s2EaxY1tHqrhVghObs5FnMvC83XFQmq3l5mUc/CQfV5q4mFLfdjZGg8MiiMWLOm/CGnEzKwt7E3XSjW772BxnbU4XUh4hzVlnfr7wHtMPsVHWnr4wouLmHTi7OdYZJp4J/TBMbul5LRe7/nHV7oosUzZvk3wsGpxv2n4Os9nd0pH2ItI2iN3OVFOp0O8lNUI8rEZCxso2qdj+TWf7V8eTwbr0o0jdKYeK7ecwvh9W80ujHgUXqhDU3cMiftwlDhrLcOqzLOSa7kNQJzw4oYcwXp115nHWdrbnm/bvd2O31Vb1rdf2sLA1j7L5/NIY9aZzE3dLe5zZb9zlOAksjq89adVG8rGtj9VjW1fcZSw/b0s5u1ZYy8e5+jNW8tW7hUUTlCdsP4fZkVabPY+yNQ7acQ6zOSxsTxe2X4c5wm+sGoPVdd9nMT+H2a4xZZyGsjmtNnUeZe28KmlwGZiQZnLnjlh1wl/5ZDQaUVVVVf3q7t7IvqVN1HVGJqR9uzgPJ1d8jtxcLeQHjdk5DhXF+cj96i0cN6ukaWl6bPghi/2vhNKDXf8eSaxdScOdXoY3liQhRys8XiEq10KzdwPmTEoC70CNcFlY9tYSJGVrYZDHFK0yQHshDRvemoiki9Ky9kjug1tXWX3DyUnBs/0K3DJrMi2Txi4waYHj4MT7L6/ATbFXgSbBB4Dc9cU55BXpUd1Qx1iFm0UFyPxC04iLA0ZXgkPrzyD/msnYMbfKULjvBHYty4XY8VvjGM9fRYFwrcd/u4IVjuV1MQ6OcO4UKPaPHCQtY3Q/ZgsDJ5rtcz2Mx1mhdmseruikDxvLoT15BrtX56NA2xS5UxU0Xx5DRnZZzfbcrsD187nYv+oojrfXwm4LxA978IE1d607Y5EmKqFjaSJj3RHrlTTc5SKksf25a7xqxH6LcTEXhdcsukxrtCoUfnkEu3cWmIz1xNZn0ItxfbnFzUZ7sOPzy2Yx3VXcrl6DuO/pWdi9sukraZpTg8OioAh7V53AqfNlNfvNK5GvXcWpreyYN7KShrM7zjYjbfJJ7E+/hpvV+yxvTzp+OVn/0OHXD1yG3JBUmyV2kdsUGrNNbUZRCU7su4grLN7VSkc8D/mHRSUNp9Ph2MqjOJh+Fddv1TGguyVdGQ4tP4pDFt8xGsT0ejDVNFTsOIex/GC/cF6Vflsqd2SsP4GMLGthUYYjn2XhDE9HBnklfHt4HnWOpTErN5MKrmH/6mPIPFkKncl3mo4d+abN+90W2R4WbTGPapPsSastpaFlHMbWcrbNWqA80SLni2bPo1pAC4SF7ddhVbiSeAK7t+U1Q3lZ1C7KE/acVyXNdz1CSNtDLWraKAoLQu4/Td+ihjQ9+Sle4Hr6Mey1eDKKdz/Se2IfhPIxDrJO3jMDcrY1Vp+gI+QeUetpXdL2deqMYb8Pg6fxGjI+PNcE49MQQmzi4IVBcyIRwMdVlFp1E0IIIYS0BdSihhBCCGmLXDwRKHS1Uoq8fbWfxjRqdSjIo6c0CSHk3uGI4CdChcHFbx4voEoaQlqD2gPCWNnX5bElCSGEEELuP1RRQwghhNjMC6GPecDTYiBE76GhiH6AD3hchctnqDUNIYS0aS7OCH7hAXGsk1tFOPH9vdJ9CCH3Kg/0nhKIIJOBzB2COmHw6EBh7IHr2WVN1vUgIYQQQsi9hro+a6MoLAi5D0wvw4WxtQd/oa7P2jIH+I3vh8ERvDKmLkZUZJ9B6ldljR4H4n5ldTDLuw26S0hrkQfKt0Bdn7Vd8uDg1Yw6nNlwEtmNHReJEHIX9QwmrWXn+X+w8zyNP0AIIYSQNoS6PiOEEELaJCOufHUUu5PEwSLNBiy9XSEM6pj5xRHsokoaQghp+6oH46VKGkJaRhmOCwNCV7ISFScNAr7vBHZRJQ0hhBBC7nPUoqaNorAghBBCCCGEEEIIIYQQQloHtaghhBBCCCGEEEIIIYQQQgi5D1BFDSGEEEIIIYQQQgghhBBCSCsx6/qMEEIIIYQQQgghhBBCCCHkfkddnxFCCCGEEEIIIYQQQgghhNwHqKKGEEIIIYQQQgghhBBCCCGklVBFDSGEEEIIIYQQQgghhBBCSCuhihpCCCGEEEIIIYQQQgghhJBWQhU1hBBCCCGEEEIIIYQQQgghraRDSEjIHelvK4bDd+qfENZFgfJjn+Pkt5tglN6pV8BMBD85HH5+KjhVVwXpcH7dsyi6JM3eS6YtR/LT4UBuIhJeWSctJIAvFs54DP1c2Z+afZj4VR704hstr98wfDsqWJqRafDd0r34VJqrS9ee0Xj/cTWUFUX46esf8EGR9EZD+ffBxheioCzLxAdrT+InaXHL8sDrLzyKR/ydoD+Vijf/W4SL0jut6TfxY/FSXxf2lwbJH+7FmgZlIIQQQgghhBBCCCGEENK67twRq074K5+MRiOqqqqqX93d3YX3m0L9LWq6jIB/F4XwIWW/h6ESl9av94eInvoEggJMK2lI+2RAZaX0p7Gq9SppGmlUPzWUPK66+mNgHw9xYWvyD8X7z/8aXz1lWfFUD/9gDPTnFSKOUPbuiVHi0lanrTRIfwGVVElDCCGEEEIIIYQQQgghtdRflXJpN4ouGYRWNPpjP0MnLq1HDPzi1HBmv6o/ux0ZS57F/oWjpekebU1D6mGEQbr5bqiouSHfKo7txVNLv5SmvciVFjfErmNZ0PP9KC/C4ZNl4sLW5B+MyEBvKDpK8w1RpMHholvsjyroT53FLnFpq6u8XSX9YWhA/kEIIYQQQgghhBBCCCH3n7u0edmD4nVP4uDC0TjeoG7P+sPNl70YspD31UpU3KJbs+2bDleui39V6svFP+5BF89mYOKHX+KpVXZ0e9ZmlOGDLxLx1NJ/Y2Ib6faM+6VUygPKdbhnDy0hhBBCCCGEEEIIIYQ0o7tU1NioSwiU/PWmrrqlBSGEEEIIIYQQQgghhBBCCLGuQ0hIiDgijgmPF3agd5g0I8v9Gvu/WCvN1KHLO+gzNQbupenI+HgeKqTFjTMVy5PHIjw3EeO+88Hy38chwBXQH1qHye8XYer7f0R8mJItyEHivFlYd1r6GqeMxaQ/T0J8dDC8FdKyci00h7Zj1cebkWllUBXvuBn464vDEe6rhMJRXGYwAAr+fbYNCa+sExfKlFGY8OoMPDGkZh0GrQbp363CR19l3rPjtjSVhFFP4uV+KqBgH17ZnFe7pYdDF7z/ShwinbT45dP/4v0ScbHS2QPjY/viwR5d4O8uHdjbt6AtyELyzixsqbeHsmB88MYwhEGD75buxafSUjP+fbDxhSixYrFaGQ5/kYR36mn6ofTwxyuPDcDAIJOuySqrACcWWcoy8cHak/hJWszHixnYPRS/eagnenWWP18Fww0tzqfvw3sZOmiFzwGPjBiD16MbMD7Ohb14aqtGmgFeevZ5/KabNCOz+EwtDipMjIvGo327wJtvN1ehxcWjR7BmXxGOmVay9huGb0cF4+L3X+LNglC8/et+iPRl4cmrePWXcHjXPryT03Td3sX9eT3+OCIAiuI0LPvDIqTc7wmIEEIIIYQQQgghhBDSKu7cEatO+CufjEYjqqqqql/d3d2F95tCo1vU8EqdB9+WJl5Jwxd6xSBaXiZPL0wTPm83RzUWzhQraTjloHj89X+lShphQTjGvDxB/JvrNRXLN8zFBJMKFIGrN4KHTcLiT+Yi3uwuvRLxs9fj09ljoPavqaThhEoaa5TxWLBmMSYNM1+HwjsYsZMXY838eIuKgPtP8uFssTIiMBQJzsIiM8q+4Yh0Yn8UZGGjVEnDjX9iDH4THVpTScN1dIF3t2hMnDQML7XCgY3sNQRr/mckHupmMX6MXNlhyb8XXh87BP3MxptxhMLdF5EjnsQHIzxaPn4og/HB75/EOF55abrdzt7oOmQkFr7YB49ayRX8+o/Emt8NRaSfVEnDKbtg4FOPYZ6/NN9ocRg+KABCiPvGYszzwkJCCCGEEEIIIYQQQghp16y2qDEzYCUeHBNeZ4saq61vrGlIixyrpBY1/E9DDhLfeguK17ZgjNSKQHtgGV45GYdPp0RBUZaOJRPmIxXBmLF6NcYEsw/oc5C0Zgk+36WBXhmM+N/+EZOeVsPbkX1373xMXJwu/tCIBdjy5xgoYUDhgc345/rtSNPoAd9wxE6Zi7lxARYtapSY8MFGTOqlgD47CetWbEJKtla4ER775FT8z29jEKDQIm3BRCw6IH3FRnHzt2D2kLvdytcj/e/jMH83+7N6H+qnP7AE4xakSnPNzREvT/gtEoKAi6n/xiuHpcHlJXKLEMv3XnpiDAbqM/Ft+iX8cqNKaJnU1ccfLz89Ev28WNilb8NLP9U1BlIDWtSY8cC8aWx9HvW0qHFmvzmd/aYT25acA/iUxafv9Wx7HRwR2Ssa7/y6J4t/Fi1q/NVY8ZgSp38+jeSLOuRWsmVOCjw6YChefrgLFMY8fPfhvtrbJ7ViuWvLGEt3/V5NWOBGHpK3H8DGy2x/2D482jsaE0f1hLcDT1OJeOnnW+JX5N/kjGwfUlPxQWYZtE7eeP2FX2MgCwvDiZ0Yn1IsfqaRqEUNIYQQQgghhBBCCCGkLbinWtSUfTEa+xdK07p03OALeddn8jJ5squSxlzh7lVYd1qPU4XS3duydKxdkAJtiQH8Hni16OcwiN9bNmiQNG8WVvFKGr5cr0HK+jfw1rYc8M6avKPGII4vZyaMEbvB0h/4CFMWbBYrabjiHKRprdwt7vYihvdSAJdS8PZrq8RKGo6tI23TfMzfXchmvBH+qyhx+X2rChuPise7a2QouooLRc6hGMjDqTIHv2SYV+B8uj0Jr+zW4Hupkoa7WFKEt9PFCghvnwZ0E9aE+g1SI8yJRakL+/Dmt3liJQ1nrMKZa+Xm8U9WlIVX/nUIK85LlTRcpQHfHziC47zrNgdP+PmKi1uERzgG8kqaSg2SN+7DGl5Jw5ezffj+xCHM+0Ejpgt1OB7hy00ZtTi8eRtezyjDRSOL5hVafHBIDAuFu9TMrQmk/n0KnkpIQMIkqqQhhBBCCCGEEEIIIYTcHxpdUdNyNDj0zyzpb1HhvnWw2i5kUDAC2Ishdw9WmY5ZI9GszWS/xnj4oIewJA7qLrzDJS2O7m5gS5Oh4RB6fOoSj6XJyUi2mFaP5lsA+ASohVd7pC4YhwR+07reSWpNw+2ej3FWP2M+tVxrGpH+dB7O84qKwGA8ZdL9Wde+oejKYqA+6yw2mo6Lwjmp8PKoOHz6ym/x7RvP10xy646OdXQ31kwGBoo1KhdPaWqPs1OPfhFqfPC7MfjqTyb78AZvvcPfdTTrYq/ZhfoLcdZw/izWWKkEuXgsR6iE4elCaMFmSnMC71yW/pboC0uqK9EIIYQQQgghhBBCCCGE2OceqqgxwGBxV1hfbr1bqLguYiVJ5XXeqsWacyixOhh9CYr2Sn/ejUohjqVBGqAIP2bxbsq64IFBLuIiOCIhogt71eLYYXlIfYlzF3ww7Ukk9OsCb+eWrZCpXxm016Q/G+CRh3+NhU9GI8zPA4o2kNIe8fUUXiv15cJrbTpo6+pNjhBCCCGEEEIIIYQQQkizuIcqahouvUgcld7JU6ywqa0HrPecpYRPtPRnQ/Fxa6y0WpGnp17fLH3QdnyMGsuWOrWnLVgwQvoCH6PG6mfMpy3z5Q7fWk7y4Wzw6hj/HiHoxxfwbs94N1wFWdgoBle1gTFRCOO9aVVcwk+JiXhp6Zd4Sp52Wa+caxkuUIl1HXfn0AWPD/AW/tSe3YsVK0z2YWkSDlutKGxeh69dF16dlHV1VaaCt0r6kxBCCCGEEEIIIYQQQkiLaJcVNfqiEmGsDUVYDCZZGVlf/fsYCB1oFWmQLizRQmxk4AP/vhZf6DUJSx+r1RHU/2/v3uOjqu/8j7/lMkCHREJTEpEEm1BL1CWgRqyIG6gYmg1UUdwgFtFy6QrUii7iUsgG6qLZCkUurkDR8hNhCwTElJKlhmzZqBgUg4VQNCiOYtJlGQ0ZCQMZfuc2IZfhHpIQXs9HT8/5fs6ZnDPnfMc/zofP9ytt98iq1+mWEPIcqOPQXr39hbGOjNePOhu3rVeMooyn9NcPPq03lFivaDvB4dvzvuZ8UmkleIK+36Fp6pgqjlo9Sl26BCuCHK3CNXlQgjW/US3fiVC3tuaGR2//waM/HbWitlYutbX2nUGr1vX/7gXwfVVh/y6+e41Ghvjlfz8x3hqKTgfL9J4dAgAAAAAAAABcZC0yUaN1uSoyKxZcCUp/cbbSb4uxX3i7Y5QyYb5mDo2RS36VvLVSRWbc+P8te810gEsJ9z6rR282EwURShqRqWXPpish1NvyHVu0p8xYm+d4Zb4eu6efYho4YdNS5qixVWnFByXGXY9QXEK47jaHPTvm0c69zu4a7KSI8bi6f1epzpw23TpHauLdaXrudmtmoEa38SNnov2kAZre3U6gdLvqGs0Zk6Y7okIkj44ckz2KWJR6JrY3vrWhrUt33tBHL/3sLvU63fz7X9sJFcX00qw+4XbypCHsL9GH5u+ibbyGP9RHwzs7iaBWrXVnn9s0Y6D9u9i3o0Q7zXgTSH5ymdablV/LpymlgX9PAAAAAAAAANAcXREbG3vC2XaM1TUz7rUm4z+1Eu2eOUH1Rm/qOkvXj0lS2FeF2vHCdNUsIjh/YzR/4zDFG+fMTp2kpUbEHBJsSl+3StalatISI2AO+fVkktzlhcpKz5CZhnAPytTix5PsF+Qh+Pas0ozJy1XstNXdOM884zz13rn7VLz1Y8X2T5TbHOZsonkFNvegKZo/IVnRpyzyOHnNMLTqqucmJuv7R8rlCw+Xdv5RIzfXmZ/G4O7eR4vvC1GlYjpSKX+H9nLt36q715wcBu3h+x7Qj7s7jVPYt/k1TXYyEHcMTNPkPiHHv6vm25GjkXnBXh6up36aph90cprV/Cp75yMdu/V6dSsv0pwlu/RnK+7SxAfu051XWY3aAsZ3OGZ8h3bleu/VHM0yE361nOpchlrfO0ZznuivOKcVmkevP79VLzst91XXa0F6oiJOkfzx7c3XzDcO6K9OW736a/2gmDrndURdrxUPGr+LUPvOS7IyV01RkvNYqn/fAAAAAAAAANDITpywUyfm2lwCgYCqqqqq12FhYdb+htAyK2oMvs0ZGjd1uQr2e+WvcoIGv9ejglee1uiaSRrT/qWaOmO5Cj0+J2D8jbJi5WSN0xObvDrsxGrybc7SI1MXKXdXqXx2EQhOJ3BA/11cIYWHyy2vdr5XP0lj8u3foec2FOlzX/DBVcl/+KD+mrdBD6/9q4450cZVrueWb9DGknLjezihrzx6e0OOJhcYz7/eRfm1YLV5vNH/gscfr5TX+G4rfputP1rj5p2Kc649B42/W6PzNgDfl7s08bdv6m3zd3HcCQaM+3vI/C7ZGlczSdPo8rVle6ldTXSwQDmvWUEAAAAAAAAAaNFCVNQAAAAAAAAAAABcvqioAQAAAAAAAAAAuAyQqAEAAAAAAAAAAGgiJGoAAAAAAAAAAACaCIkaAAAAAAAAAACAJkKiBgAAAAAAAAAAoImQqAEAAAAAAAAAAGgiJGoAAAAAAAAAAACaSK1ETVxcnNq3b++0AAAAAAAAAAAAcDFRUQMAAAAAAAAAANBESNQAAAAAAAAAAAA0ERI1AAAAAAAAAAAATYREDQAAAAAAAAAAQBMhUQMAAAAAAAAAANBEroiNjT3hbCsuLk4HDhxQZWWlE8Fp3bhQt6bFO42gEu2eOUHlTuu0Oo1Ql7Shujo2Qu3aODFDac5gffq+0wBOI/zBTbouzmkE7Vurd15d4jTOgD4IAAAAAAAAAPWcOGGnTsy1uQQCAVVVVVWvw8LCrP0NgYqaphL5lK6d+JDi4mq/IEcNAx/V8y+t0Pp5Y5wAGhR98IySJzyvl1as1/yxTgAAAAAAAAAAGhgVNQ1mrK6Zca+iz6qipqPC7n9N1/d06diBQu3NnqPDh7zOPlQbO18b74mX9mUrdeJSJ4hTClZ4nVVFDX3wbIxZsFHD4qSSdamadJZFSgAAAAAAAAAufVTUtHhJ+la0y1h75Vk/nRfkaAL0QQAAAAAAAABoDkjUNIke6tDJXB9S5UErADQy+iAAAAAAAAAANActe+izVr3lTh6rmF4xCg93WVmpgN+rgx/k6Yu8JTrqtw+rJXqCYoYOUFSXjmpjfCBwvELle7bok5yFoY+vdi5Dn53LsecqQkn3jNKwwbcooWuEXK3tqL+8VCVbl+tXC/NVq3bCGV7Ms2G4Ju98SDPHDlBClNve5/Oo8D9/o4w1xXbbNDBTq59MkrbP0/DX3Jr22L1K6uacx7i3JZsWaep/FMhnH32Su59GPTlKKX1iFGEWcpiOeOXZ/oYWvbBKRc4HkjNWa0pf5/ync6kMh+YaoE53jVDX62LVsb2dGT1eUaqyd9fqy7fe0PGAfVgt59sHz2nos+bTB+3hxTzKGT5ZRT+ZqZ/+MEHR1V2wUCvnZih7j922nG8f7Jmmx346TLf3jJb7lNeUrMxVU5QUbjVOi+HQAAAAAAAAgJarMYc+a8GJmiRFjpmlHl2dZh2H331OuzZtcVq2NjcuVGJavNo67VoqS7R70QSVVzjtek7/4rvd4DXqc0tHp3UaXxVqxwvTddRpnjPnJfapUh3ebfM0LjP35EtsJ1HjLyvVsajoEJ/zqfDXw5WR5zSDf7+8VKXto2WNnlWLXyXrJmnSEo/TNvQco/nPDFN8B6dd18ECzfunZ5RrXFSLStS0GqGYyQ/p6m857TpKcwbr0/edhuOC+uAZEjXNtQ/aiRq/SsuOKTqYJKypvFBZ6RnKd5rn0wfdg6Zp8c/7KcJJ0NTl/yhbTz+2VMUkagAAAAAAAAAYGjNR03KHPou7VzFmkuarD7Rr0Ti9M3Owsdynd38zV7vf/6x+ZULkU+qRGq+2laX6ZM0svfsr83hjmTNXe/ZWKNA+XtemPuQc3Jz5daisWLlLntGkUalKTTWWUZM0b7PH2CNF9E3TCPvAWlxWksankj/M0/jhqRo+fpEKrRIDtxLvGmYdU0u4+YLcr9Jty5VhnmdUhnL2mWdwKb7vMMXYRxli9OjjTpLGV6KcueM13Lym4eM1b02xvFVGPLKfRv08yTo6P3O4fc3msq7EillJmWAsuFxQkmaM5m/cqI1nWhaMcY4/P61uTbGSNMc/36KiOSOcPjhC7y5eoo/3enXiuHNg0GXdB112kqa6jwzX+P8otKtcwhOVco91UG1n3QfT9MtxdpLGX1ao5TNGOteUoaX59jW5vpemMT8xk0T5ykh3rtlYsvdZf8BKygRjwYUkDQAAAAAAAICG0HITNe3bKfiP54+Xf+ZsVShQnqvynHH6OK92NU2HW5PUqZVfX6yfqLLdBQoEh6SqyNVXq1bqi2+kNnG9db45sqOb7nNe1JvLWpVaUbP6JhhzlgupZDDlPaPxDz+heesKVBKce+RgiXLnrlSRVebTWVH9rWgdXhXOHa1JC3Pl8ZlDTuUoa6tdkeDq2Nla12ZWLTytRzJXqdA8z8FCLXq9yK6SMI6PN9emPiN0s/nG3O9RzvRJWrTZYx/j8yh32ROauqHEfnmfmKZkM96CtApWehyv0LFvgoN9eRUoXauDq0Zo/04n5Ljs+6C3UPNGB/uIT54NWSrYb+5wqWOkdUQdZ9kHRwxQgpmDKS/UixMztGq78yyM47Ozxus328xPuJTQd8Qpq4AAAAAAAAAA4GJpuYmaPZvkOWSsO/VW4pQ16jnsKYXFVr+6raO33N3MIaFcujp9jW6dsanOMlYx5vBVrgi1syZgb87cSrx/mua/vFrr36hZIRIczsklV6hxtfZtUcZm6xV3Nd/eUvuldyjlRVq7pMbcNabNHuflfw03xyjaWPmNv7+o5jwjDs+SIlnpoPDO6mFFGsNSTapTHRFyucCh1Y5vL1BppdTmmiG6cepKxQ2eIHdkrLO3LvpgSX6GNfzdST7tLj1lDzzrPph8baxxRqn0/ew6f9+Wn/eBXbkTGSO7rgsAAAAAAAAAGk/LTdQEclW2aJY1zNkRdVSnGwbo+tELdesvzaTNBLWrNa9FhFrXm+fi0pT89GLNHt1P8VHu6kncm1JyVzNNIx37ul4Kx/GxDjXsTPbNR8USfbpooTXMWaBVhLrcMkR/9+hi3fIvKxU3cITa1Pr10Qcvlh7fsetkfN4ia13P1jKZOV0AAAAAAAAAaAotN1FjChRYw5wV/WqE3n3ld9r3l1InaTNEieOmq51z2EkV+mRpnWGgai2jdfAr59DmyD1KQ/pGWJveXdmaN77GfC+pWSpsgoRIYZn9CrztlXbCpr4e6nwWE7c3rMaZo8ZS8YY1zNn2fxun9157Q5/sc5I2tz+kxPvHhvgB0gcbmueQXUbjjki01vX0j1Kowf0AAAAAAAAAoDG07ERNNa8Cn63U37JHqyjrd9ZcH606J6pTV2e3tuibA+ZMKR317Z6X8OBHfeMVa1VleFTwr0uVa042E+TuHHrIs4vMV3bInqw9LkmjQkwAkvCzJHvS9zKPCq1ICK1dl/7cIYHPdOzjhSp7dYS2L9hiVXC0vba30eOC6IMXy+6Dh6119A1pIYY2cytlUG+ZqSX/gWLl28F6XK2ZvQYAAAAAAADAxdFiEzXt7nxFPdNnKTy298lJ3RWhVtGxatfG3D4mHbeClsO7S8yIwm+frmvTxqpDR7sqoLlwD5qiZWvtSo/V/z5KCU68Fq9P9ivpKCWMTrJePisyXimPzNay5WOU2MHa2bjW5doTyLsSlP7ibKXfFmMnXdwxSpkwXzOHxshlTgr/1krVG5jqYIWV5FH3AXp2QopiGuxdeePMUROevkY90h6XOzpBrYK/tFaxats1Qla+ImBFqjX3Ppjwk+e12ppzZr2WTUkJnTxrhn3Q8/pbKjE7UmQ/TXvxMaV8z7mvkUlKz5ivf7rZ/CY+FeWssuM1HKqweqBifvisHh3k9F0AAAAAAAAAaEBXxMbGnnC2FRcXpwMHDqiystKJXLraDV6jPrecrFeo6+jetSpataTGu/IEhd03SwnXdTxl9urwu89p16YtTksKf3CTrotzGqdQmjNYn77vNKqN1TUz7lW0SrR75gSdzWhQo+ZtVPr3nIa8KsgcqWe2Oc1qCXps6fNKqa4Uqskvv98ll8unwl8PV0aeEx47XxvviZf2ZddPTAzM1Oonk+SuuS8YKy9UVnpGnQoEc0ixYYqvs889KFOLH3de2ofg27NKMyYvV51p4Q3JmrZiivqF+mCo621mztQ/yv/nOe3OO9mfzr0PBvvR6Zyqj51rH0zStOWZ6hfpNKtKtGrIJC13miedex8cs2Cjhhn3qWRdqiYtsWNByRmrNaWvu/a+8+iDCUY/n23089DTAPlVmv+iJmXlqkb9j23gNK14sl/IvhvqegEAAAAAAAC0DCdO2KkTc20ugUBAVVVV1euwsDBrf0NosRU1R/Oe04d5xfqq3K/jwWyMsT568DN9suE57aiVpDEV6/Ca0dqxvlB/O1jjM83E2px8lR6xt727cpVdL0ljKta8qVnK+cgrf5UTqvLLu79Ay6eOVM7nTqyR+TZnaNzU5SrYX+O6DH6vRwWvPK3RIZM0pnw985jxfXaVymcXNlxSytfM1e53P1P5N/6TfS3gl6+0WB8vn1onSWNqzn2wUNmbi+Uzn1+VT56tOVpr76ijefbB4iWT9HBWjorLfLWuy1dWrJysh/VIqCSNKe8ZTaz7OQAAAAAAAABoQC22ogYAAAAAAAAAAOB8UFEDAAAAAAAAAABwGSBRAwAAAAAAAAAA0ERI1AAAAAAAAAAAADQREjUAAAAAAAAAAABNhEQNAAAAAAAAAABAEyFRAwAAAAAAAAAA0ERI1AAAAAAAAAAAADSRWomaffv2qbKy0mkBAAAAAAAAAADgYqKiBgAAAAAAAAAAoImQqAEAAAAAAAAAAGgiJGoAAAAAAAAAAACaCIkaAAAAAAAAAACAJkKiBgAAAAAAAAAAoIlcERsbe8LZDmGAIsc8rriuLh3Z+TvtWr9SAWfPaUVPUMzQAerSpaPaVqeCKvTJ0vtUdsBpXkrGztfGe+KlfdlKnbjUCUKK1MxH71KvDsam5y2N/P2n8tk7Lindru2j5/4hQe6jZfrz2jc1p8zZ0YDu6PtDTbwtSq6KYq1YvkOrjzo7mlC3pGQtuKOrsVWh917boFlf2nEAAAAAAAAAuNydOGGnTsy1uQQCAVVVVVWvw8LCrP0N4fQVNV0HKqqryzrI3et2dbSjp3fdXPUZM0RXR9dM0qBl8uvYMWczUHXGJM0dN92sBQ/fpzm9nEAzMahXgtxmX+0QpZuuD7eDDSpcf98rSi7zHOEJ+sH37WhT+/xolbMVsP4HAAAAAAAAAGh8p0+lHMhT2QG/9Q7Xt/N/VGFHTyNJXZIT1M74q769b2hH1n16Z+ZgZ7lEq2lwGgH5nRf8/qN+e+M04r97rbp1djmt5mPzzmL5zO9xpEzv7Sq3gw2qXP+9s8y+V+XFevuvdrTJHQ8mavzyHXE2AQAAAAAAAACN6vSJGm3RwaVD9e7MwfrwrIY9661vRRorf7E+/f1CHa08c2oHl7IK/e1re+vYJfym//O9OzRy7mu6e9HFGfbM9Odtb+p+8xxLmsewZ5b/+9qpgjoi78XITwEAAAAAAAAAzugMiZpz1DVWbnP9TUV1pQUAAAAAAAAAAABCuyI2NtaeEaeG8Ac36bo4pxG0b63eeXWJ0ziFrrN0/ZgkhX1VqB0vTFfDFA6M0fyNwxS/L1vDX++s+T9LVnQHybd9qUY/V6Yxz/1CKXFuI1Ci7OmTtHSP8zGTu59GPTlKKX1iFBEcceuIV57tb2jRC6tUFGJSlYjkR/XLhwYoPtItV2s75vdLLvPzxjWkTlxqB4PciUr/+aMa0vfkOfxejwpfX6Tf/L7okpxcv+GEa/rYNN10FtO+7Nv8mibvdBqK0Zwn+iuuvEhzluzSV9+7XuMGJKhbmHGDzblwvvyLfv/GLr1e6+a21k3fvUY//sG16vmdCLnamLEq+Q979UnhW3p2R4W81nGOqOu14sFEO7FYrVzvvZqjWaGqapzjVZSjkW+79NSPknRTjHEeM9V5zKt9/71V04sqaj/vXv21flCM0wjy6PXnt+plp1WLc/znf3pNT31xjWb8qJe+H9nRTqf6Dui9zW9pVkndIeZa644+fTQy6RpFmfcnlP1bdfcaj9O4AAOnaNkE4/fn8qrghXF6ZvPl3bsBAAAAAAAAtFwnTtipE3NtLoFAQFVVVdXrsLAwa39DuOCKGjOpc+sMZzGTNGawU5L6BGPB5cGx1vHnrXWCZpoviTvYTffNKfrlvzhJGisQr7Rx6fa2qecYzV8+Tek1EiiWDhGK6T9Ks1+cppRab+ndSpmyTC9PSVNC1MkkjclK0oTiTlHm4tka1b/2OVwRMeo3erYWZ6TUSQTg3HTQD4YM1cyhiXaSxtSqtdxXJ+rhB67XHXbEFtVTk4f1Va+rgkkaU2u5wiL1/YFDNWdgeIM8C/d3k/TSw3fpB92dJI2pbYTi7hysWb1qdJoL0KX3D7X4J7fp+12cJI3J3VU33X2Xpkc5bcedA+/S5IHXnjpJ04CS+yfZv7/WEer34xF2EAAAAAAAAABwQUJW1NRy40LdmhZ/yoqakNU3oZxNRU5ITkWNuekvUfbUqXI9tlpp3a2d8m6bp4m7kvXyI4lylRcqKz1D+YrRoy+9pDSzmMFXopzFWfrdZo987hil/OMvNOqeBEW0Nj67NUMjZxfaf2hgplY/mSS3/Crdtkq/XfaGCjw+KTJe/R6ZpmnJ0XUqatxKn7NCo3q65PsoR0sXrFTuR14jHKN+Q8fop/+YZFceZI7UM9ucj5yj5IzVmtL3TOkFnwp/PVwZecZm9Xc4Pd+2LA3PzHdajefh+x7Qj43nVrt6JhSnosZp+cuKtHrjHm08VCVXl2v1bPrNimpbqZ1rsjVjv3NQVIIW3OXWnv8xjvu8QvuOGbG2Lt15420ad3tXuQKf6vW5b4WuZKmu/DlzRY19b/0q27FVi7eW6T2117gfpym1u0v6cpsmvlaiz61j6gp+pzNX1FgCxnfIz9econJ520Zo8oM/0k2djDP/5b90f+5B+5jwa/XSWONe1Dj284DU7aprNHnIbYoL82vfH9dp8u4q+/gLRUUNAAAAAAAAgMvEJVVRU/7qYL0z01mWFuqwGTSHPgvGgst5JWlqK81bpKV7fNpd6rwgLi/UksxceQ/5Zb6Xr9ZnhG4233f7PcqZPkmLzCSNGfd5lLvsCU3dUCJzAKmIxDQlm3FDepr9Et637Td6JHOVnaQxHSxRgTfEC+nuD2lAT5d0IFczHltkJ2lMxjkKVmYoI6/UaEQo/u8T7TjOg1+f/3mDHn51l1YfqrKeofdve/XOAXNfe3W80lw7yoo18f9t14JPnCSN6Zhff9r2vj40J8pvdaW6RNrhC+PXvs0bND6vTO+Z5zlWqcUFH9n9y92+Orl0QQJevbdqgybvsBMvvqNezdluD13mCnNKykwd2qqjuf5yp2Y5x5o+//JTzSo0b5JLUdENUUfkyMvSI/emKnXISJI0AAAAAAAAANBALjhR03g82v7bYmfbVvrWUoWsC7k5RtHGyr9vixbVnLPG4VlSZPw1Q3hn9bAiyUroag4d5dUHeWdZaXJbvKxRqLqm6PmNG7WxzvLSYPMKpM7RCdb6fORnDldqauoZFqeaxpSXoeEhj6m9NEU1zfkp03uFdeZ9Mby85jXd/Xz9qpxe30vQnJ+k6fePP6D1TwSX4Bw5rWsNZ3feyou1fmedeWK+PGRcaQPy/EWzvnS2Hb7SQ/Xug44cU4W5vqqXpvcJVzfn12xW1ExP6mptVxytO6cNAAAAAAAAAKA5uYQSNX7567yp9h0JPUF6clc7SXLsa7OqJZSPdcissqjnkMq2Optn0tGliz8rCM7WHbf/SDOH9lFcl/CTc8e0dOV79frOCuNX3FFxA9O0wElQLXjAHPbM2P9VkVa/XWkfCwAAAAAAAABollrkK+3CskPWuu2VdsKmvh7qbFVZ1OVW5z7O5tky560JUbUSXO6evMo58NyZc9TUrdSpv6xW5kDnA+YcNSGPqb2szggO+NZCtOqqf7gxwtr07t2qBQvsiht7ydF7IZNyLUCrSN0a31E6XKbPD1VKztBnOubV5zvy9dzLu/SnYAwAAAAAAAAA0Cy1yESNr+yQNQeNKy5Jo0JM0ZHwsyRZU7aXeVRoRbzyHTHXnRV1Q50P9Byl5++Kdxo1bPfIqtfplhDyHDg11xXORkP5ToS6tTU3PHr7Dx796agVtbVyqa21r+Xp1ucG9TL63ufb3tTEl7N191wnOfXCHzUx74DeJkkDAAAAAAAAAM1eyxwkal2uiswqCleC0l+crfTbYmTlUtwxSpkwXzOHxsglv0reWqkiM278/5a9XmPtUsK9z+rRm83qjAgljcjUsmfTlRAqEbNji/aYE5OY53hlvh67p59iGjhh09LmqDl02B6Gq9sP+mvcVa3tZ9IQgnO1KEo9E9vLqq1p69KdN/TRSz+7S71qzL/fksRd2dFad0mI153h7dUrrAHvaSgDp2jZ2o3a+MYKTRt0Uc8EAAAAAAAAAJeNK2JjY084246xumbGvdZk/KdWot0zJ6jeiFJdZ+n6MUkK+6pQO16YrpqFDedvjOZvHKZ445zZqZO01IiYQ4JN6etWybpUTVpiBMwhv55Mkru8UFnpGTLTEO5BmVr8eJL90j4E355VmjF5uYqdtrob55lnnKfexDM+FW/9WLH9E+U2hzmbaF6BzT1oiuZPSFb0KSerOXnNMERdr5cfSFREiPTgvs2vafJOp6EYzXmiv+Lk0evPb9XLTvTUXJr4wH268yqnWVOgUv5j7eVqV673Xs3RLGfW/zsGpmlyn5Dj31Xz7cjRyDynlxvXvuJBow+UF2nOkl36sx11ONdbZ9/D9z2gH3d3GqdQ63v36q/1g2Kk/Vt195o68y8Fz19z32nup1Ql/+EyfbjlHc35qNLoxRcu+Luz1PktAAAAAAAAAEBLcuKEnTox1+YSCARUVVVVvQ4LMycKbxgts6LG4NucoXFTl6tgv1f+Kido8Hs9KnjlaY2umaQx7V+qqTOWq9Bz8pW2r6xYOVnj9MQmrw47sZp8m7P0yNRFyt1VKp851hpOr2yXJq94S3/9W7n8DTosl18LVm/QxhLjWQf/7vFKeffv0IrfZuuP1hh1LdD/7teH/+t07mOV8h+pMU+NWssV1lU3DU3TrF6nzCSek/ythSo1hwis8qrg9ZV2EAAAAAAAAABwQUJU1AC4FPw4ZagevqGj/Pu3avoaj/7qxE3uduEaf+9duuMql3Rwu2b8bq+qC5YAAAAAAAAAAKdFRQ2AM4jUTfHmHDV+7dlRO0lj8h0t1+8/Oui0AAAAAAAAAADNFYka4JLmUs+kBP24i+vkfExtXbrzhj6a3rer1fSWfEY1DQAAAAAAAAA0Uwx9Blyi7rj9R5rctzo9E9qhIi343S79qUHnBAIAAAAAAACAlq0xhz4jUQNcwnrFxGtkcoK+2zlcrjZOMOCX/6syfVi4Qwv+UiGvEwYAAAAAAAAAnB0SNQAAAAAAAAAAAE2kMRM1zFEDAAAAAAAAAADQREjUAAAAAAAAAAAANJFaiZq4uDi1b9/eaQEAAAAAAAAAAOBioqIGAAAAAAAAAACgiZCoAQAAAAAAAAAAaCIkagAAAAAAAAAAAJoIiRoAAAAAAAAAAIAmQqIGAAAAAAAAAACgiVwRGxt7wtlWXFycDhw4oMrKSieC07pxoW5Ni3caQSXaPXOCyp3WaXUaoS5pQ3V1bITatXFihtKcwfr0facBnEb4g5t0XZzTCNq3Vu+8usRpnAF9sIEd1Zu5ZerhtILK37laf5fR2mk1njELNmpYvf6RrdSJS53GqcWMmK05DyTK7S9V/sJHlJXn7GhAyU8u0y8GRstVXqTlTz2tVfudHResSit//4Vuu9JpBn39bf3qfrfO8tcBAAAAAACAy9iJE3bqxFybSyAQUFVVVfU6LCzM2t8QqKhpKpFP6dqJDykurvYLctQw8FE9/9IKrZ83xgmgQdEHzyh5wvN6acV6zR/rBC4jKf0S5TZzSx2ildQ/2Q42qGQNuDlaLnMzPFH97rKCp3Q5PwsAAAAAAAC0bCRqLsT7E/TOzMHOslalTvjMOipsYD91Nu7+sQOF2rVgRI2/QyVDtfgEJcREyNX4hQiXjPJXT/abd3JKnOjZoA+ejR4JCYqJsFIJ58as3EiJVXdnaYpqGtPSialKTXWWdefSP6TcgiL5qoyNI6Uq3JpvBxtUvrZsL5Xf3CwvUsF/WcFTOrdn0Voj7j95/7tnffvsqhwBAAAAAACAJkCipkkk6VvR5gtHrzzrp+vwIa8dBhoNfRCn51n5tIYPSVXqvRdn2DNT/q8f0d1mEim9IYc9AwAAAAAAAC4tJGqaRA916GSuD6nyoBUAGhl9EAAAAAAAAACagytiY2PtGXEMcXFxOnDggCorK53IJa5Vb7mTxyqmV4zCw11WVirg9+rgB3n6Im+Jjlpj7tQRPUExQwcoqktHtTE+EDheofI9W/RJzsLQx1cbq2tm3KtolWj3zAlnGGbnXI49VxFKumeUhg2+RQldTw4b5i8vVcnW5frVwnzVqp0YO18b74mXZ8NwTd75kGaOHaCEKLe9z+dR4X/+Rhlriu22aWCmVj+ZJG2fp+GvuTXtsXuV1M05j3FvSzYt0tT/KJDPPvokdz+NenKUUvrEqHr0oiNeeba/oUUvrFKR84HkjNWa0tc5/+mc5YToTc41QJ3uGqGu18WqY3s7M3q8olRl767Vl2+9oeMB+7BazrcP3rhQt6bFG/dmrd559UzTpTefPmhPeO9RzvDJKvrJTP30hwmKru6ChVo5N0PZe+y25Xz7YM80PfbTYbq9Z7Q994qh/jUlK3PVFCWFW43TKlmXqkn1bvNRvZlbph7nOGl99aT6Bws075+eUW69i28Azm/9tL8d597W/gX6VPjr4cqoW1UTfA7bsjRj3xDNvD/BuK9+ef7wjMa/GaPZ/zJGiZHGcXW/U/A6ailRduok1b6qC30WNfzQpw+n/J/Cz/G5AAAAAAAA4PJ14oSdOjHX5hIIBFRVVVW9DgsLs/Y3hBZcUZOkyEee1d/dHq9OTpLG1MoVoS633KseAwc4kZPa3LhQN40boquj7RfkplZtOqrTDUPU5xcLFd7Rjp2PdoPX6NYZm5zFfEFuitd11TFn+fkstbP2naeBv9CUsSlKrDO3iys8Wgn/MEULMlLqvIS1RfWdr1d+mXYySWNyxyjpkZnKHOi0a3Bf+49a9uwY9ete4zzGvY0f+s96dmyME3D0HKP5y6cpvW+NJI2pQ4Ri+o/S7BenKeUscjOXnFYjFPPzp9TzxliFO0kaU5uO0bp64AR16+0Earh8+2CUbl7wiqYNPZmkMbljkjTmXzMVair7c+mD7kHTtOLfH1XK9SeTNKbgNb08b4wSnFjjqzGpfmQ/pT1gBS8dVw7RP48wkzRmw2X8ptM1+7FRdpLGZHynf5yQ6DQAAAAAAAAA1NVyEzVx9yqmq7H+6gPtWjTOmST9Pr37m7na/f5n9SsTIp9Sj9R4ta0s1SdrZundXzkTq8+Zqz17KxRoH69rUx9yDm7O/DpUVqzcJc9o0ihnEvFRkzRvs8eatDuib5pG2AfW4oqKlls+lfxhnsYPT9Xw8YtUaJUYuJV41zDrmFrCoxXt8qt023JlmOcZlaGcfeYZXIrvO0wnX5PH6NHHhym+g7HpK1HO3PEabl7T8PGat6ZYXnOy8sh+GvXzJOvo/Mzh9Sc/NysAgrHgckHVNGM0f+NGbTzTsmCMc/z5aXVriq7+lnT88y0qmhOcrH+E3l28RB/v9erEcefAoMu6D7oUbSYJq/vIcI3/j0K7yiU8USn3WAfVdtZ9ME2/HNdPEa2NKysr1PIZI51rytDSfPuaXN9L05ifmBmifGWkO9dsLNn7rD9gVWwEY8HltBUc56TGpPoHC5TzmhVsGnkZ9u/TWrJUeBalVu6eCYr2Fmre8Hn28eEJSuxu3rMn9MTmUuuY6Fj7921ZMqnGfcyW8ysPoSmeBQAAAAAAAND4Wm6ipn07Bf/h/PHyz5ytCgXKc1WeM04f521xYrYOtyapUyu/vlg/UWW7CxQIDklVkauvVq3UF99IbeJ663yLmY5uus95UW8ua2W/vjSHnQrGnOWF6Tpq7TtPec9o/MNPaN66ApUE5x45WKLcuStVZL107ayo/la0Dq8K547WpIW58vjMIadylLXVY+1xdexsrWvzq2Td03okc5UKzfMcLNSi14vs4aaM46sHNuozQjebb8z9HuVMn6RFmz32MT6Pcpc9oakbSuyX94lpIasmLmWtgtVDxyt07JvgYF9eBUrX6uCqEdq/0wk5Lvs+aL7sHx3sIz55NmSpwJpg3qWOweqMWs6yD44YoAQzB1NeqBcnZmjVdudZGMdnZ43Xb7aZn3Apoe+IkNVmjaF6Uv1RF2nYs4vKp6I1WcZ1G//tcJ63f5/x348lxSquuOS+DAAAAAAAANDoWm6iZs8meQ4Z6069lThljXoOe0phsXXnRQjqLXc3c0wpl65Orzk8VHAZq5hvmbsj1M6agL05cyvx/mma//JqrX+jZoVIcK4Hl1xtrQNr27dFGZtrv1T17S21X3qHUl6ktUtqzF1j2uxxXv7XcHOMNcSW3/j7i2rOM+LwLCmSlQ4K76weVqQxLNWkOv8iP+RygXPgHN9eoNJKqc01Q3Tj1JWKGzxB7shYZ29d9MGS/Iw6SQqfdpee5kX/WfbB5GtjjTNKpe9nh0yC5Od9YFfuRMaoRt0Hzlb5buWvq3lj/Sp+c6n9uwYAAAAAAABwRi03URPIVdmiWdYwZ0dkzvExQNePXqhbf2kmbSaoXc25UhSh1rXal67kpxdr9uh+io9y15ofpKkkd7VnQjn2db0UjuNjHWrYmeybj4ol+nTRQmuYs0Arc26kIfq7Rxfrln9ZqbiBI6rnoLHRBy+WHt+x62R83iJrXc/WMpk5XZy/2hVYx+T/2tkEAAAAAAAAcEYtN1FjChRYw5wV/WqE3n3ld9r3l1InaTNEieOmh5gwvUKfLK0zDFStZbQOfuUc2hy5R2lI3whr07srW/PG15jv5Sznm2hohWX2K/C2V9oJm/p6qLNVZdGYGmeOGkvFG9YwZ9v/bZzee+0NfbLPSdrc/pAS7x8b4gdIH2xonkN2tYc74hQT2vePUqjB/QAAAAAAAACgMbTsRE01rwKfrdTfskerKOt31lwfrTonqlNXZ7e26JsD5kwpHfXtnpfw4Ed94xVrVWV4VPCvS5VrTjYT5O4cesizi8xXdsiag8YVl6RRISYASfhZkj3pe5lHhVYkhNauJps7pMEEPtOxjxeq7NUR2r5gi1XB0fba3kaPC6IPXiy7Dx621tE3pIUY2sytlEG9ZaaW/AeKlW8H63G1vuR7YIvBswAAAAAAAEBL02ITNe3ufEU902cpPLb3yUndFaFW0bFq18bcPiYdt4KWw7tLzIjCb5+ua9PGqkNHuyqguXAPmqJla+1Kj9X/PkoJTrwWr0/2K+koJYxOsl4+KzJeKY/M1rLlY5TYwdrZuNbl2hPIuxKU/uJspd8WYydd3DFKmTBfM4fGyGVOCv/WStUbmOpghZXkUfcBenZCimIa7P1s48xRE56+Rj3SHpc7OkGtgr+0VrFq2zVCVr4iYEWqNfc+mPCT57XamnNmvZZNSQmdPGuGfdDz+lsqMTtSZD9Ne/ExpXzPua+RSUrPmK9/utn8Jj4V5ayy4zUcqrB6oGJ++KweHeT03Ysg+cllWm9WcS2fppSLdZJLXGM9CwAAAAAAAKCxXREbG3vC2VZcXJwOHDigyspKJ3Lpajd4jfrccrJeoa6je9eqaNWSGu/KExR23ywlXNfxlNmrw+8+p12btjgtKfzBTbouzmmcQmnOYH36vtOoNlbXzLhX0SrR7pkTdDajQY2at1Hp33Ma8qogc6Se2eY0qyXosaXPK6W6Uqgmv/x+l1wunwp/PVwZeU547HxtvCde2pddPzExMFOrn0ySu+a+YKy8UFnpGXUqEMwhxYYpvs4+96BMLX7ceWkfgm/PKs2YvFx1poU3JGvaiinqF+qDoa63mTlT/yj/n+e0O+9kfzr3PhjsR6dzqj52rn0wSdOWZ6pfpNOsKtGqIZO03GmedO59cMyCjRpm3KeSdamatMSOBSVnrNaUvu7a+86jDyYY/Xy20c9DTwPkV2n+i5qUlauaU+JbBk7Tiif7hey7oa7XnK3lzdwy9fj62/rV/W7V2x1SsjJXTVGSMwRg6L97Ppx74bRCK1F26iQFf0nB+306vm1ZGp5p3NkQz8F+ljWeb4j/vgSf9+mEvAfn/Cxq+KFPH075P4Wf03MBAAAAAADA5ezECTt1Yq7NJRAIqKqqqnodFhZm7W8ILbai5mjec/owr1hflft1PJiNMdZHD36mTzY8px21kjSmYh1eM1o71hfqbwdrfKaZWJuTr9Ij9rZ3V66y6yVpTMWaNzVLOR955a9yQlV+efcXaPnUkcr53Ik1Mt/mDI2bulwF+2tcl8Hv9ajglac1OmSSxpSvZx4zvs+uUvnsf0x/SSlfM1e73/1M5d/4T/a1gF++0mJ9vHxqnSSNqTn3wUJlby6Wz3x+VT55tuZorb2jjubZB4uXTNLDWTkqLvPVui5fWbFysh7WI6GSNKa8ZzSx7ucaXL62bC+1q8cOFijnNSuIuhrlWQAAAAAAAACNr8VW1ABA4zufihpcdFTUAAAAAAAA4BxRUQMAAAAAAAAAAHAZIFEDAAAAAAAAAADQREjUAEBDu/L/9Mvcz7TfWT7MZFKVxlWllb8/ef/3m8OeOXsAAAAAAACA5oZEDQAAAAAAAAAAQBO5IjY21p4RxxAXF6cDBw6osrLSiQAAAAAAAAAAAFxeTpywUyfm2lwCgYCqqqqq12FhYdb+Cyf9f/YXK8Koo5vMAAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "0kjl4yWvJdrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![2.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "L01v5PSDLbIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloning the CATR repository"
      ],
      "metadata": {
        "id": "CQco62sDf0eG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiJsz7pJyQVA",
        "outputId": "7a907f09-3530-4b7b-9787-d88c4dd22367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'catr'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 121 (delta 48), reused 36 (delta 36), pack-reused 57\u001b[K\n",
            "Receiving objects: 100% (121/121), 3.05 MiB | 17.95 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/saahiluppal/catr.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## changing directory"
      ],
      "metadata": {
        "id": "pvwHArWEiPp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd catr/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkujJvZJyXoM",
        "outputId": "ba138455-4ef7-47b1-b6ff-f5e981b0b3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/catr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing all dependencies"
      ],
      "metadata": {
        "id": "bEwblVUVibpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0USBJe1Tgq02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmvaq8uWyasb",
        "outputId": "eacb62e8-46fb-47f4-f037-3092cee437b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.21.6)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 15.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (4.11.4)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r requirements.txt (line 4)) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting with google drive for loading data"
      ],
      "metadata": {
        "id": "gvOmuLlpi4cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVF8Z_UCydNs",
        "outputId": "e7cf2e36-fb6c-4920-bfe7-47e7a7ce09eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model with our new Bangla dataset"
      ],
      "metadata": {
        "id": "Tj51IzWxjXuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NhBuaEMy54b",
        "outputId": "499dfd4d-c060-45c1-fc12-a80deffefb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100% 171M/171M [00:00<00:00, 203MB/s]\n",
            "Number of params: 83959866\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 687kB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 29.0kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 496kB/s]\n",
            "Train: 7323\n",
            "Valid: 1830\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Start Training..\n",
            "Epoch: 0\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/content/catr/models/position_encoding.py:38: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n",
            "100% 228/228 [11:21<00:00,  2.99s/it]\n",
            "Training Loss: 0.9568671509528908\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [03:02<00:00,  3.14s/it]\n",
            "Validation Loss: 1.2837119466612107e-05\n",
            "\n",
            "Epoch: 1\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:15<00:00,  1.91s/it]\n",
            "Training Loss: 7.320287125909536e-06\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:56<00:00,  1.03it/s]\n",
            "Validation Loss: 2.609124200309201e-06\n",
            "\n",
            "Epoch: 2\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:16<00:00,  1.92s/it]\n",
            "Training Loss: 2.000584209171345e-06\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:55<00:00,  1.04it/s]\n",
            "Validation Loss: 9.917476404552872e-07\n",
            "\n",
            "Epoch: 3\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:17<00:00,  1.92s/it]\n",
            "Training Loss: 8.753984928445565e-07\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:55<00:00,  1.05it/s]\n",
            "Validation Loss: 4.212697060156329e-07\n",
            "\n",
            "Epoch: 4\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:19<00:00,  1.93s/it]\n",
            "Training Loss: 4.4586119186537315e-07\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:56<00:00,  1.03it/s]\n",
            "Validation Loss: 3.445890968123422e-07\n",
            "\n",
            "Epoch: 5\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:16<00:00,  1.91s/it]\n",
            "Training Loss: 3.459099362969123e-07\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:59<00:00,  1.02s/it]\n",
            "Validation Loss: 7.442354263899092e-08\n",
            "\n",
            "Epoch: 6\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:16<00:00,  1.91s/it]\n",
            "Training Loss: 1.2474804606074884e-07\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:58<00:00,  1.01s/it]\n",
            "Validation Loss: 5.029138313457695e-08\n",
            "\n",
            "Epoch: 7\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:16<00:00,  1.92s/it]\n",
            "Training Loss: 6.218318589870215e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:58<00:00,  1.02s/it]\n",
            "Validation Loss: 3.719585522346812e-08\n",
            "\n",
            "Epoch: 8\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:16<00:00,  1.91s/it]\n",
            "Training Loss: 4.4170898735922235e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:56<00:00,  1.03it/s]\n",
            "Validation Loss: 2.7865734394279587e-08\n",
            "\n",
            "Epoch: 9\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:16<00:00,  1.91s/it]\n",
            "Training Loss: 3.3400074667025196e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:57<00:00,  1.00it/s]\n",
            "Validation Loss: 2.0489091251216325e-08\n",
            "\n",
            "Epoch: 10\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:18<00:00,  1.92s/it]\n",
            "Training Loss: 2.6060684378523903e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:56<00:00,  1.03it/s]\n",
            "Validation Loss: 1.6763804474841248e-08\n",
            "\n",
            "Epoch: 11\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:15<00:00,  1.91s/it]\n",
            "Training Loss: 2.0877909077978628e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:55<00:00,  1.04it/s]\n",
            "Validation Loss: 1.2107192551195959e-08\n",
            "\n",
            "Epoch: 12\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:15<00:00,  1.91s/it]\n",
            "Training Loss: 1.6857242705040028e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:56<00:00,  1.03it/s]\n",
            "Validation Loss: 1.2107192551195959e-08\n",
            "\n",
            "Epoch: 13\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:16<00:00,  1.92s/it]\n",
            "Training Loss: 1.4071828318569196e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:55<00:00,  1.04it/s]\n",
            "Validation Loss: 7.450580137521197e-09\n",
            "\n",
            "Epoch: 14\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [07:15<00:00,  1.91s/it]\n",
            "Training Loss: 1.1506862238880994e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:55<00:00,  1.05it/s]\n",
            "Validation Loss: 7.450580137521197e-09\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iLjtkDK1z7jB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}